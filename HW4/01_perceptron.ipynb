{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"positive class:\", sum(data.target == 1))\n",
    "print(\"negative class:\", sum(data.target == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```imbalanced classes```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=22, sampling_strategy='minority')\n",
    "X_tr_sm, y_tr_sm = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "lr_sm = LogisticRegression(solver='liblinear').fit(X_tr_sm, y_tr_sm)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pr_sm = lr_sm.predict(X_test)\n",
    "\n",
    "score = precision_recall_fscore_support(y_test, y_pred)\n",
    "score_sm = precision_recall_fscore_support(y_test, y_pr_sm)\n",
    "\n",
    "print(\"performance of Logistic Regression without oversampling\", score)\n",
    "print(\"performance of Logistic Regression with oversampling\", score_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=None).fit(\n",
    "    X_train, y_train)\n",
    "rf_sm = RandomForestClassifier(n_estimators=100, n_jobs=None).fit(\n",
    "    X_tr_sm, y_tr_sm)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pr_sm = rf_sm.predict(X_test)\n",
    "\n",
    "score = precision_recall_fscore_support(y_test, y_pred)\n",
    "score_sm = precision_recall_fscore_support(y_test, y_pr_sm)\n",
    "\n",
    "print(\"performance of Random Forest without oversampling\", score)\n",
    "print(\"performance of Random Forest with oversampling\", score_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conclusion: using SMOTE for oversampling will result in a minor improvement```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data = MinMaxScaler().fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=22, sampling_strategy='minority')\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find implementation of perceptron in perceptron.py\n",
    "import perceptron as pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = pn.Perceptron()\n",
    "perc = perc.fit(X_train, y_train)\n",
    "print(perc.errors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = perc.predict(X_test)\n",
    "score = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(\"precision: \", score[0])\n",
    "print(\"recall: \", score[1])\n",
    "print(\"fscore: \", score[2])\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Further optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different train-test split factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [0.20, 0.25, 0.30, 0.35, 0.40]\n",
    "accs = []\n",
    "for f in factors:\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
    "        data.data, data.target, test_size=f, random_state=22)\n",
    "    X_train_, y_train_ = sm.fit_sample(X_train_, y_train_)\n",
    "    perc = pn.Perceptron()\n",
    "    perc = perc.fit(X_train_, y_train_)\n",
    "    y_pred_ = perc.predict(X_test_)\n",
    "    acc = accuracy_score(y_test_, y_pred_)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(factors, accs)\n",
    "plt.xlabel(\"train-test split factor\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```accuracy changes 5 percent at most```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using larger epochs size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_sizes = [100, 200, 300, 400, 500]\n",
    "accs = []\n",
    "\n",
    "for e in epoch_sizes:\n",
    "    perc = pn.Perceptron(epochs=e)\n",
    "    perc = perc.fit(X_train, y_train)\n",
    "    y_pred_ = perc.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(epoch_sizes, accs)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "accs = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    perc = pn.Perceptron(lr=lr)\n",
    "    perc = perc.fit(X_train, y_train)\n",
    "    y_pred_ = perc.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(learning_rates, accs)\n",
    "plt.xlabel(\"learning rates\")\n",
    "plt.ylabel(\"accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
