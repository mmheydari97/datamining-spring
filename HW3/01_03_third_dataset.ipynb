{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "1   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "2   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "3   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "4   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "\n",
       "   ca  thal  disease  \n",
       "0   0     2        1  \n",
       "1   0     2        1  \n",
       "2   0     2        1  \n",
       "3   0     1        1  \n",
       "4   0     2        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"../Dataset/Dataset3.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242 entries, 0 to 241\n",
      "Data columns (total 14 columns):\n",
      "age         242 non-null int64\n",
      "sex         242 non-null int64\n",
      "cp          242 non-null int64\n",
      "trestbps    242 non-null int64\n",
      "chol        242 non-null int64\n",
      "fbs         242 non-null int64\n",
      "restecg     242 non-null int64\n",
      "thalach     242 non-null int64\n",
      "exang       242 non-null int64\n",
      "oldpeak     242 non-null float64\n",
      "slope       242 non-null int64\n",
      "ca          242 non-null int64\n",
      "thal        242 non-null int64\n",
      "disease     242 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 26.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df3.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generalize numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age:  {34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77}\n"
     ]
    }
   ],
   "source": [
    "print(\"age: \",set(df3[\"age\"].values))\n",
    "df3[\"age\"] = df3[\"age\"].map(lambda x: x//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trestbps:  [94, 100, 101, 102, 104, 105, 106, 108, 110, 112, 114, 115, 117, 118, 120, 122, 123, 124, 125, 126, 128, 129, 130, 132, 134, 135, 138, 140, 142, 144, 145, 146, 148, 150, 152, 154, 155, 156, 160, 164, 170, 172, 178, 180, 192]\n"
     ]
    }
   ],
   "source": [
    "print(\"trestbps: \",sorted(set(df3[\"trestbps\"].values)))\n",
    "df3['trestbps'] = (df3['trestbps']-min(df3['trestbps']))//np.std(df3['trestbps'])\n",
    "df3['trestbps'] = df3['trestbps'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chol:  [126, 131, 141, 149, 157, 160, 164, 166, 167, 168, 172, 174, 175, 176, 177, 178, 180, 182, 183, 186, 187, 188, 192, 193, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 239, 240, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 281, 282, 283, 284, 286, 288, 289, 293, 294, 295, 298, 299, 300, 302, 303, 304, 305, 307, 308, 309, 311, 313, 315, 318, 321, 322, 325, 326, 327, 330, 335, 340, 341, 342, 354, 360, 394, 407, 409, 417, 564]\n"
     ]
    }
   ],
   "source": [
    "print(\"chol: \",sorted(set(df3[\"chol\"].values)))\n",
    "df3['chol'] = (df3['chol']-min(df3['chol']))//np.std(df3['chol'])\n",
    "df3['chol'] = df3['chol'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thalach:  [88, 90, 95, 96, 99, 103, 105, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 190, 195]\n"
     ]
    }
   ],
   "source": [
    "print(\"thalach: \",sorted(set(df3[\"thalach\"].values)))\n",
    "df3['thalach'] = (df3['thalach']-min(df3['thalach']))//np.std(df3['thalach'])\n",
    "df3['thalach'] = df3['thalach'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oldpeak:  [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.8, 1.9, 2.0, 2.2, 2.4, 2.5, 2.6, 2.8, 2.9, 3.0, 3.1, 3.2, 3.4, 3.5, 3.6, 4.0, 4.2, 4.4, 5.6, 6.2]\n"
     ]
    }
   ],
   "source": [
    "print(\"oldpeak: \",sorted(set(df3[\"oldpeak\"].values)))\n",
    "df3['oldpeak'] = df3['oldpeak']*10\n",
    "df3['oldpeak'] = (df3['oldpeak']-min(df3['oldpeak']))//np.std(df3['oldpeak'])\n",
    "df3['oldpeak'] = df3['oldpeak'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0    3    1   2         2     2    0        1        4      0        2      0   \n",
       "1    5    1   1         1     2    0        1        4      0        0      2   \n",
       "2    5    0   0         1     4    0        1        3      1        0      2   \n",
       "3    5    1   0         2     1    0        1        2      0        0      1   \n",
       "4    5    0   1         2     3    0        0        2      0        1      1   \n",
       "\n",
       "   ca  thal  disease  \n",
       "0   0     2        1  \n",
       "1   0     2        1  \n",
       "2   0     2        1  \n",
       "3   0     1        1  \n",
       "4   0     2        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df3.drop(['disease'], axis=1)\n",
    "y = df3['disease']\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Classifying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.datasets import load_wine\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "dtree_gini = DecisionTreeClassifier(criterion='gini')\n",
    "cls = dtree_gini.fit(X_train,y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "export_graphviz(dtree_gini, out_file=\"./03/dtree_gini.dot\",\n",
    "                feature_names=X_train.columns,\n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "dtree_entropy = DecisionTreeClassifier(criterion='entropy')\n",
    "cls = dtree_entropy.fit(X_train,y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "export_graphviz(dtree_entropy, out_file=\"./03/dtree_entropy.dot\",\n",
    "                feature_names=X_train.columns,\n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "rf_gini = RandomForestClassifier(n_jobs=-1, n_estimators=50, criterion='gini')\n",
    "rf_model = rf_gini.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "export_graphviz(rf_gini.estimators_[0], out_file=\"./03/rf_gini.dot\",\n",
    "                feature_names=X_train.columns,\n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "rf_entropy = RandomForestClassifier(n_jobs=-1, n_estimators=50, criterion='entropy')\n",
    "rf_model = rf_entropy.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "export_graphviz(rf_entropy.estimators_[0], out_file=\"./03/rf_entropy.dot\",\n",
    "                feature_names=X_train.columns,\n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to see each tree in jupyter notebook\n",
    "# uncomment following lines and execute them in \n",
    "# separate cells\n",
    "\n",
    "# graph = Source(export_graphviz(dtree_gini, out_file=None,\n",
    "#                                     feature_names=X_train.columns,\n",
    "#                                     filled = True))\n",
    "# display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "\n",
    "# graph = Source(export_graphviz(dtree_entropy, out_file=None,\n",
    "#                                     feature_names=X_train.columns,\n",
    "#                                     filled = True))\n",
    "# display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "# random forests have many estimators so we should travers them\n",
    "# or just visualize one of them\n",
    "\n",
    "# graph = Source(export_graphviz(rf_gini.estimators_[0], out_file=None,\n",
    "#                                     feature_names=X_train.columns,\n",
    "#                                     filled = True))\n",
    "# display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "\n",
    "# graph = Source(export_graphviz(rf_entropy.estimators_[0], out_file=None,\n",
    "#                                     feature_names=X_train.columns,\n",
    "#                                     filled = True))\n",
    "# display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'min_samples_split': [2, 5, 10],\n",
    "        'max_depth': [5, 10, 15, None]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search on decision tree with gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886010</td>\n",
       "      <td>0.880829</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.887179</td>\n",
       "      <td>0.895656</td>\n",
       "      <td>0.014041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.050068</td>\n",
       "      <td>2</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.911917</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.923524</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.907044</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.911917</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.932642</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.929725</td>\n",
       "      <td>0.012205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.907044</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2        0.003972      0.000221         0.001858        0.000030   \n",
       "1        0.003906      0.000495         0.001846        0.000296   \n",
       "11       0.002850      0.000525         0.001295        0.000298   \n",
       "0        0.004390      0.000252         0.002151        0.000053   \n",
       "8        0.003335      0.000494         0.001419        0.000269   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "2                5                      10   \n",
       "1                5                       5   \n",
       "11            None                      10   \n",
       "0                5                       2   \n",
       "8               15                      10   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "2      {'max_depth': 5, 'min_samples_split': 10}           0.836735   \n",
       "1       {'max_depth': 5, 'min_samples_split': 5}           0.775510   \n",
       "11  {'max_depth': None, 'min_samples_split': 10}           0.816327   \n",
       "0       {'max_depth': 5, 'min_samples_split': 2}           0.734694   \n",
       "8     {'max_depth': 15, 'min_samples_split': 10}           0.816327   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "2            0.918367           0.795918  ...         0.822314   \n",
       "1            0.877551           0.795918  ...         0.797521   \n",
       "11           0.877551           0.734694  ...         0.789256   \n",
       "0            0.897959           0.775510  ...         0.785124   \n",
       "8            0.877551           0.714286  ...         0.776860   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "2         0.056929                1            0.886010            0.880829   \n",
       "1         0.050068                2            0.906736            0.911917   \n",
       "11        0.062540                3            0.906736            0.901554   \n",
       "0         0.062128                4            0.911917            0.922280   \n",
       "8         0.078004                5            0.906736            0.901554   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "2             0.906736            0.917526            0.887179   \n",
       "1             0.927461            0.943299            0.928205   \n",
       "11            0.917098            0.917526            0.892308   \n",
       "0             0.932642            0.948454            0.933333   \n",
       "8             0.917098            0.917526            0.892308   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "2           0.895656         0.014041  \n",
       "1           0.923524         0.013000  \n",
       "11          0.907044         0.009574  \n",
       "0           0.929725         0.012205  \n",
       "8           0.907044         0.009574  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1 = GridSearchCV(dtree_gini, param, cv=5,\n",
    "                   n_jobs=-1, iid=True,\n",
    "                   return_train_score=True)\n",
    "gs_fit1 = gs1.fit(X, y)\n",
    "pd.DataFrame(gs_fit1.cv_results_).sort_values('mean_test_score',\n",
    "                                             ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search on decision tree with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886010</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.902564</td>\n",
       "      <td>0.895635</td>\n",
       "      <td>0.012629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.059515</td>\n",
       "      <td>2</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.004064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.923508</td>\n",
       "      <td>0.014255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.056813</td>\n",
       "      <td>4</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.912821</td>\n",
       "      <td>0.909085</td>\n",
       "      <td>0.005365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.047197</td>\n",
       "      <td>5</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.930751</td>\n",
       "      <td>0.011334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       0.003905      0.000402         0.001708        0.000222   \n",
       "8       0.001869      0.000291         0.000823        0.000115   \n",
       "1       0.004693      0.000928         0.001905        0.000356   \n",
       "5       0.001914      0.000065         0.000848        0.000032   \n",
       "0       0.003239      0.000592         0.001452        0.000224   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "2               5                      10   \n",
       "8              15                      10   \n",
       "1               5                       5   \n",
       "5              10                      10   \n",
       "0               5                       2   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "2   {'max_depth': 5, 'min_samples_split': 10}           0.836735   \n",
       "8  {'max_depth': 15, 'min_samples_split': 10}           0.795918   \n",
       "1    {'max_depth': 5, 'min_samples_split': 5}           0.734694   \n",
       "5  {'max_depth': 10, 'min_samples_split': 10}           0.755102   \n",
       "0    {'max_depth': 5, 'min_samples_split': 2}           0.714286   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "2           0.877551           0.795918  ...         0.793388        0.061700   \n",
       "8           0.836735           0.755102  ...         0.768595        0.059515   \n",
       "1           0.857143           0.775510  ...         0.764463        0.065014   \n",
       "5           0.836735           0.775510  ...         0.760331        0.056813   \n",
       "0           0.836735           0.755102  ...         0.752066        0.047197   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "2                1            0.886010            0.875648   \n",
       "8                2            0.906736            0.906736   \n",
       "1                3            0.906736            0.906736   \n",
       "5                4            0.906736            0.901554   \n",
       "0                5            0.917098            0.917098   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "2            0.906736            0.907216            0.902564   \n",
       "8            0.917098            0.912371            0.907692   \n",
       "1            0.927461            0.938144            0.938462   \n",
       "5            0.917098            0.907216            0.912821   \n",
       "0            0.937824            0.938144            0.943590   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "2          0.895635         0.012629  \n",
       "8          0.910127         0.004064  \n",
       "1          0.923508         0.014255  \n",
       "5          0.909085         0.005365  \n",
       "0          0.930751         0.011334  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2 = GridSearchCV(dtree_entropy, param, cv=5,\n",
    "                   n_jobs=-1, iid=True,\n",
    "                   return_train_score=True)\n",
    "gs_fit2 = gs2.fit(X, y)\n",
    "pd.DataFrame(gs_fit2.cv_results_).sort_values('mean_test_score',\n",
    "                                             ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search on random forest with gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186716</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948187</td>\n",
       "      <td>0.948187</td>\n",
       "      <td>0.953368</td>\n",
       "      <td>0.953608</td>\n",
       "      <td>0.964103</td>\n",
       "      <td>0.953490</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158939</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.105984</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.064221</td>\n",
       "      <td>2</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.911917</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.919411</td>\n",
       "      <td>0.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155226</td>\n",
       "      <td>0.017278</td>\n",
       "      <td>0.105592</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.050899</td>\n",
       "      <td>3</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.927642</td>\n",
       "      <td>0.013277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147678</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.958974</td>\n",
       "      <td>0.945216</td>\n",
       "      <td>0.007924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.184520</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.104903</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>4</td>\n",
       "      <td>0.911917</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.932642</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.929725</td>\n",
       "      <td>0.009777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       0.186716      0.010457         0.111165        0.003896   \n",
       "2       0.158939      0.010751         0.105984        0.002601   \n",
       "1       0.155226      0.017278         0.105592        0.002009   \n",
       "0       0.147678      0.010194         0.104645        0.000509   \n",
       "5       0.184520      0.008824         0.104903        0.000476   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "4              10                       5   \n",
       "2               5                      10   \n",
       "1               5                       5   \n",
       "0               5                       2   \n",
       "5              10                      10   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "4   {'max_depth': 10, 'min_samples_split': 5}           0.897959   \n",
       "2   {'max_depth': 5, 'min_samples_split': 10}           0.897959   \n",
       "1    {'max_depth': 5, 'min_samples_split': 5}           0.877551   \n",
       "0    {'max_depth': 5, 'min_samples_split': 2}           0.857143   \n",
       "5  {'max_depth': 10, 'min_samples_split': 10}           0.877551   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "4           0.938776           0.775510  ...         0.859504        0.056369   \n",
       "2           0.959184           0.816327  ...         0.855372        0.064221   \n",
       "1           0.938776           0.816327  ...         0.851240        0.050899   \n",
       "0           0.938776           0.795918  ...         0.847107        0.054392   \n",
       "5           0.918367           0.775510  ...         0.847107        0.048474   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "4                1            0.948187            0.948187   \n",
       "2                2            0.917098            0.911917   \n",
       "1                3            0.927461            0.906736   \n",
       "0                4            0.943005            0.937824   \n",
       "5                4            0.911917            0.927461   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "4            0.953368            0.953608            0.964103   \n",
       "2            0.922280            0.922680            0.923077   \n",
       "1            0.927461            0.927835            0.948718   \n",
       "0            0.937824            0.948454            0.958974   \n",
       "5            0.932642            0.938144            0.938462   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "4          0.953490         0.005812  \n",
       "2          0.919411         0.004333  \n",
       "1          0.927642         0.013277  \n",
       "0          0.945216         0.007924  \n",
       "5          0.929725         0.009777  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3 = GridSearchCV(rf_gini, param, cv=5,\n",
    "                   n_jobs=-1, iid=True,\n",
    "                   return_train_score=True)\n",
    "gs_fit3 = gs3.fit(X, y)\n",
    "pd.DataFrame(gs_fit3.cv_results_).sort_values('mean_test_score',\n",
    "                                             ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search on random forest with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.105390</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.924571</td>\n",
       "      <td>0.005473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.173521</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.105176</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.926617</td>\n",
       "      <td>0.009141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.163835</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.105837</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911917</td>\n",
       "      <td>0.927461</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.927637</td>\n",
       "      <td>0.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.161257</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 2}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.060276</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.144343</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.104912</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.939025</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        0.145746      0.012286         0.105390        0.001238   \n",
       "5        0.173521      0.010256         0.105176        0.000824   \n",
       "11       0.163835      0.005746         0.105837        0.000625   \n",
       "6        0.161257      0.013688         0.106127        0.003668   \n",
       "0        0.144343      0.005004         0.104912        0.000893   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "1                5                       5   \n",
       "5               10                      10   \n",
       "11            None                      10   \n",
       "6               15                       2   \n",
       "0                5                       2   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "1       {'max_depth': 5, 'min_samples_split': 5}           0.877551   \n",
       "5     {'max_depth': 10, 'min_samples_split': 10}           0.877551   \n",
       "11  {'max_depth': None, 'min_samples_split': 10}           0.877551   \n",
       "6      {'max_depth': 15, 'min_samples_split': 2}           0.877551   \n",
       "0       {'max_depth': 5, 'min_samples_split': 2}           0.836735   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "1            0.938776           0.836735  ...         0.863636   \n",
       "5            0.918367           0.836735  ...         0.855372   \n",
       "11           0.918367           0.816327  ...         0.855372   \n",
       "6            0.938776           0.775510  ...         0.847107   \n",
       "0            0.938776           0.816327  ...         0.842975   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "1         0.049882                1            0.922280            0.917098   \n",
       "5         0.043306                2            0.922280            0.917098   \n",
       "11        0.037885                2            0.911917            0.927461   \n",
       "6         0.060276                4            1.000000            1.000000   \n",
       "0         0.051302                5            0.943005            0.922280   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "1             0.927461            0.922680            0.933333   \n",
       "5             0.922280            0.927835            0.943590   \n",
       "11            0.917098            0.932990            0.948718   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "0             0.943005            0.932990            0.953846   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "1           0.924571         0.005473  \n",
       "5           0.926617         0.009141  \n",
       "11          0.927637         0.012894  \n",
       "6           1.000000         0.000000  \n",
       "0           0.939025         0.010660  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4 = GridSearchCV(rf_entropy, param, cv=5,\n",
    "                   n_jobs=-1, iid=True,\n",
    "                   return_train_score=True)\n",
    "gs_fit4 = gs4.fit(X, y)\n",
    "pd.DataFrame(gs_fit4.cv_results_).sort_values('mean_test_score',\n",
    "                                             ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Unknown Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_val = pd.read_csv(\"../Dataset/Dataset3_Unknown.csv\")\n",
    "res3 = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_val[\"age\"] = df3_val[\"age\"].map(lambda x: x//10)\n",
    "\n",
    "df3_val['trestbps'] = (df3_val['trestbps']-94)//17.521\n",
    "df3_val['trestbps'] = df3_val['trestbps'].astype('int8')\n",
    "\n",
    "df3_val['chol'] = (df3_val['chol']-126)//54.007\n",
    "df3_val['chol'] = df3_val['chol'].astype('int8')\n",
    "\n",
    "df3_val['thalach'] = (df3_val['thalach']-88)//22.15\n",
    "df3_val['thalach'] = df3_val['thalach'].astype('int8')\n",
    "\n",
    "df3_val['oldpeak'] = df3_val['oldpeak']*10//11.762\n",
    "df3_val['oldpeak'] = df3_val['oldpeak'].astype('int8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with decision tree using gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_gini = DecisionTreeClassifier(criterion='gini',\n",
    "                                   max_depth=5,\n",
    "                                   min_samples_split=10)\n",
    "cls = dtree_gini.fit(X_train,y_train)\n",
    "y_pred = cls.predict(df3_val)\n",
    "\n",
    "res3[\"dtree_gini\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with decision tree using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_entropy = DecisionTreeClassifier(criterion='entropy',\n",
    "                                   max_depth=5,\n",
    "                                   min_samples_split=10)\n",
    "cls = dtree_entropy.fit(X_train,y_train)\n",
    "y_pred = cls.predict(df3_val)\n",
    "\n",
    "res3[\"dtree_entropy\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with random forest using gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gini = RandomForestClassifier(criterion='gini',\n",
    "                                 n_estimators=50,\n",
    "                                 max_depth=10,\n",
    "                                 min_samples_split=5)\n",
    "cls = rf_gini.fit(X_train,y_train)\n",
    "y_pred = cls.predict(df3_val)\n",
    "\n",
    "res3[\"rf_gini\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with random forest using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_entropy = RandomForestClassifier(criterion='entropy',\n",
    "                                 n_estimators=50,\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=5)\n",
    "cls = rf_entropy.fit(X_train,y_train)\n",
    "y_pred = cls.predict(df3_val)\n",
    "\n",
    "res3[\"rf_entropy\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3.to_csv(\"./03/prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
