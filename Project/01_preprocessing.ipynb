{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "df_train.drop(\"Id\", axis=1, inplace=True)\n",
    "df_test.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = pd.concat([df_train.isnull().sum(),\n",
    "                  df_train.isnull().sum()/\n",
    "                  df_train.shape[0], df_test.isnull().sum(),\n",
    "                  df_test.isnull().sum()/\n",
    "                  df_test.shape[0]], axis=1,\n",
    "                 keys=['Train', 'Percentage', 'Test', 'Percentage'],\n",
    "                sort=False)\n",
    "print(nans[nans.sum(axis=1) > 0].sort_values(by=\"Test\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df_train.select_dtypes(include=\"object\").columns:\n",
    "    print(\"{}: {}\\n\".format(idx, set(df_train[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(df_train[\"GrLivArea\"], df_train[\"SalePrice\"])\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```there are 2 big houses with very low price.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train[(df_train[\"GrLivArea\"]>4000)&\n",
    "                       (df_train[\"SalePrice\"]<300000)].index,inplace=True)\n",
    "df_full = pd.concat([df_train,df_test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(df_full.YearBuilt, df_full.SalePrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```prices increase over years```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Sale Prices Dist\")\n",
    "sns.distplot(df_train[\"SalePrice\"], fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_train[\"SalePrice\"], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % df_train[\"SalePrice\"].skew())\n",
    "print(\"Kurtosis: %f\" % df_train[\"SalePrice\"].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Sale Prices Dist\")\n",
    "sns.distplot(np.log(df_train[\"SalePrice\"]), fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(np.log(df_train[\"SalePrice\"]), plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % np.log(df_train[\"SalePrice\"]).skew())\n",
    "print(\"Kurtosis: %f\" % np.log(df_train[\"SalePrice\"]).kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` seems like using log values is closer to normal distribution```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```values related to garage are correlated. alse basement finished area and first floor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = corrmat.nlargest(10, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.1)\n",
    "plt.figure(figsize=(12, 9))\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values,\n",
    "                 xticklabels=cols.values)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize=(16, 9))\n",
    "cols = ['SalePrice', 'OverallQual','GrLivArea', 'GarageCars',\n",
    "        'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "data_total = pd.concat([df_train['SalePrice'],\n",
    "                        df_train['TotalBsmtSF']], axis=1)\n",
    "data_total.plot.scatter(x='TotalBsmtSF', y='SalePrice',\n",
    "                        ylim=(0, 800000), ax=ax1)\n",
    "data1 = pd.concat([df_train['SalePrice'], df_train['1stFlrSF']], axis=1)\n",
    "data1.plot.scatter(x='1stFlrSF', y='SalePrice', ylim=(0, 800000), ax=ax2)\n",
    "data2 = pd.concat([df_train['SalePrice'], df_train['2ndFlrSF']], axis=1)\n",
    "data2.plot.scatter(x='2ndFlrSF', y='SalePrice', ylim=(0, 800000), ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full.drop(['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'], axis=1, inplace=True)\n",
    "df_full['TotalBsmtSF'] = df_full['TotalBsmtSF'].fillna(0)\n",
    "df_full['1stFlrSF'] = df_full['1stFlrSF'].fillna(0)\n",
    "df_full['2ndFlrSF'] = df_full['2ndFlrSF'].fillna(0)\n",
    "df_full['TotalHouse'] = df_full['TotalBsmtSF']+df_full['1stFlrSF']+df_full['2ndFlrSF']\n",
    "# df_full.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)\n",
    "# df_full.drop(['GarageArea'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"TotalHouse Dist\")\n",
    "sns.distplot(df_full['TotalHouse'], fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_full['TotalHouse'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % df_full['TotalHouse'].skew())\n",
    "print(\"Kurtosis: %f\" % df_full['TotalHouse'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"TotalHouse Dist\")\n",
    "sns.distplot(np.log(df_full[\"TotalHouse\"]), fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(np.log(df_full[\"TotalHouse\"]), plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % np.log(df_full[\"TotalHouse\"]).skew())\n",
    "print(\"Kurtosis: %f\" % np.log(df_full[\"TotalHouse\"]).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = np.log(df_full['TotalHouse'])\n",
    "sp = np.log(df_full['SalePrice'])\n",
    "plt.scatter(sf[sf > 0], sp[sf > 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"GrLivArea Dist\")\n",
    "sns.distplot(df_full['GrLivArea'], fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_full['GrLivArea'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % df_full['GrLivArea'].skew())\n",
    "print(\"Kurtosis: %f\" % df_full['GrLivArea'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"GrLivArea Dist\")\n",
    "sns.distplot(np.log(df_full[\"GrLivArea\"]), fit=stats.norm)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(np.log(df_full[\"GrLivArea\"]), plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % np.log(df_full[\"GrLivArea\"]).skew())\n",
    "print(\"Kurtosis: %f\" % np.log(df_full[\"GrLivArea\"]).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = np.log(df_full['GrLivArea'])\n",
    "sp = np.log(df_full['SalePrice'])\n",
    "plt.scatter(sf[sf > 0], sp[sf > 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean',\n",
    "                                                        'median','count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"LotAreaCut\"] = pd.qcut(df_full.LotArea,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby(['LotAreaCut'])[['LotFrontage']].agg(\n",
    "    ['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['LotFrontage'] = df_full.groupby(\n",
    "    ['LotAreaCut','Neighborhood'])['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# for remaining null values\n",
    "df_full['LotFrontage'] = df_full.groupby(\n",
    "    ['LotAreaCut'])['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\",\n",
    "      \"BsmtFinSF2\", \"BsmtFinSF1\", \"GarageArea\"]\n",
    "for col in cols:\n",
    "    df_full[col].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [\"PoolQC\" , \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\",\n",
    "         \"GarageQual\", \"GarageCond\", \"GarageFinish\", \"GarageYrBlt\",\n",
    "         \"GarageType\", \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\",\n",
    "         \"BsmtFinType2\", \"BsmtFinType1\", \"MasVnrType\"]\n",
    "for col in cols1:\n",
    "    df_full[col].fillna(\"None\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = [\"MSZoning\", \"BsmtFullBath\", \"BsmtHalfBath\", \"Utilities\",\n",
    "         \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\n",
    "         \"Exterior1st\", \"Exterior2nd\"]\n",
    "for col in cols2:\n",
    "    df_full[col].fillna(df_full[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols3 = [\"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\"]\n",
    "\n",
    "NumStr = [\"MSSubClass\",\"BsmtFullBath\",\"BsmtHalfBath\",\"HalfBath\",\n",
    "          \"BedroomAbvGr\",\"KitchenAbvGr\",\"MoSold\",\"YrSold\",\"YearBuilt\",\n",
    "          \"YearRemodAdd\",\"LowQualFinSF\",\"GarageYrBlt\"]\n",
    "\n",
    "for col in cols3:\n",
    "    df_full[\"nf{}\".format(col)] = df_full[col].replace(\"None\", 0)\n",
    "\n",
    "for col in NumStr:\n",
    "    df_full[col]=df_full[col].astype(str)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.isnull().sum()[df_full.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = [\"BsmtFullBath\", \"BsmtHalfBath\", \"BedroomAbvGr\"]\n",
    "for col in int_cols:\n",
    "    df_full[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby(['MSSubClass'])[['SalePrice']].agg(\n",
    "    ['mean','median','count']).sort_values(by=(\n",
    "    \"SalePrice\",\"median\"), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```now by studying medians we group them into 6 groups and 150 to the mode\n",
    "       180 -> 1\n",
    "       30, 45 -> 2\n",
    "       190, 50, 90 -> 3\n",
    "       85, 40, 160 -> 4\n",
    "       70, 20, 75, 80, 150 -> 5\n",
    "       120, 60 -> 6```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"nfMSSubClass\"] = df_full.MSSubClass.map({'180':1,\n",
    "                                            '30':2, '45':2, \n",
    "                                            '190':3, '50':3, '90':3, \n",
    "                                            '85':4, '40':4, '160':4, \n",
    "                                            '70':5, '20':5, '75':5,\n",
    "                                            '80':5, '150':5,\n",
    "                                            '120': 6, '60':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"nfMSZoning\"] = df_full.MSZoning.map({'C (all)':1, 'RH':2,\n",
    "                                              'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "df_full[\"nfNeighborhood\"] = df_full.Neighborhood.map({'MeadowV':1,\n",
    "                                                      'IDOTRR':2,\n",
    "                                                      'BrDale':2,\n",
    "                                                      'OldTown':3,\n",
    "                                                      'Edwards':3,\n",
    "                                                      'BrkSide':3,\n",
    "                                                      'Sawyer':4,\n",
    "                                                      'Blueste':4,\n",
    "                                                      'SWISU':4,\n",
    "                                                      'NAmes':4,\n",
    "                                                      'NPkVill':5,\n",
    "                                                      'Mitchel':5,\n",
    "                                                      'SawyerW':6,\n",
    "                                                      'Gilbert':6,\n",
    "                                                      'NWAmes':6,\n",
    "                                                      'Blmngtn':7,\n",
    "                                                      'CollgCr':7,\n",
    "                                                      'ClearCr':7,\n",
    "                                                      'Crawfor':7,\n",
    "                                                      'Veenker':8,\n",
    "                                                      'Somerst':8,\n",
    "                                                      'Timber':8,\n",
    "                                                      'StoneBr':9,\n",
    "                                                      'NoRidge':10,\n",
    "                                                      'NridgHt':10})\n",
    "    \n",
    "df_full[\"nfCondition1\"] = df_full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "df_full[\"nfBldgType\"] = df_full.BldgType.map({'2fmCon':1,'Duplex':1,\n",
    "                                              'Twnhs':1, '1Fam':2,\n",
    "                                              'TwnhsE':2})\n",
    "    \n",
    "df_full[\"nfHouseStyle\"] = df_full.HouseStyle.map({'1.5Unf':1,'1.5Fin':2,\n",
    "                                                  '2.5Unf':2, 'SFoyer':2,\n",
    "                                                  '1Story':3, 'SLvl':3,\n",
    "                                                  '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "df_full[\"nfExterior1st\"]=df_full.Exterior1st.map({'BrkComm':1,'AsphShn':2,\n",
    "                                                  'CBlock':2, 'AsbShng':2,\n",
    "                                                  'WdShing':3,'Wd Sdng':3,\n",
    "                                                  'MetalSd':3, 'Stucco':3,\n",
    "                                                  'HdBoard':3,'BrkFace':4,\n",
    "                                                  'Plywood':4,'VinylSd':5,\n",
    "                                                  'CemntBd':6,'Stone':7,\n",
    "                                                  'ImStucc':7})\n",
    "\n",
    "df_full[\"nfMasVnrType\"] = df_full.MasVnrType.map({'BrkCmn':1, 'None':1,\n",
    "                                                  'BrkFace':2, 'Stone':3})\n",
    "\n",
    "df_full[\"nfExterQual\"] = df_full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3,\n",
    "                                                'Ex':4})\n",
    "    \n",
    "df_full[\"nfFoundation\"] = df_full.Foundation.map({'Slab':1,'BrkTil':2,\n",
    "                                               'CBlock':2, 'Stone':2,\n",
    "                                               'Wood':3, 'PConc':4})\n",
    "    \n",
    "df_full[\"nfBsmtQual\"] = df_full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3,\n",
    "                                              'Gd':4, 'Ex':5})\n",
    "    \n",
    "df_full[\"nfBsmtExposure\"] = df_full.BsmtExposure.map({'None':1, 'No':2,\n",
    "                                                      'Av':3, 'Mn':3,\n",
    "                                                      'Gd':4})\n",
    "    \n",
    "df_full[\"nfHeating\"] = df_full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2,\n",
    "                                          'OthW':3, 'GasW':4, 'GasA':5})\n",
    "\n",
    "df_full[\"nfHeatingQC\"] = df_full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3,\n",
    "                                                'Gd':4, 'Ex':5})\n",
    "    \n",
    "df_full[\"nfKitchenQual\"] = df_full.KitchenQual.map({'Fa':1, 'TA':2,\n",
    "                                                    'Gd':3, 'Ex':4})\n",
    "    \n",
    "df_full[\"nfFunctional\"] = df_full.Functional.map({'Maj2':1, 'Maj1':2,\n",
    "                                                  'Min1':2, 'Min2':2,\n",
    "                                                  'Mod':2, 'Sev':2,\n",
    "                                                  'Typ':3})\n",
    "    \n",
    "df_full[\"nfFireplaceQu\"] = df_full.FireplaceQu.map({'None':1, 'Po':1,\n",
    "                                                    'Fa':2, 'TA':3,\n",
    "                                                    'Gd':4, 'Ex':5})\n",
    "    \n",
    "df_full[\"nfGarageType\"] = df_full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                                  'Detchd':2,'2Types':3,\n",
    "                                                  'Basment':3,'Attchd':4,\n",
    "                                                  'BuiltIn':5})\n",
    "    \n",
    "df_full[\"nfGarageFinish\"] = df_full.GarageFinish.map({'None':1, 'Unf':2,\n",
    "                                                      'RFn':3, 'Fin':4})\n",
    "    \n",
    "df_full[\"nfPavedDrive\"] = df_full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "df_full[\"nfSaleType\"] = df_full.SaleType.map({'COD':1, 'ConLD':1,\n",
    "                                              'ConLI':1, 'ConLw':1,\n",
    "                                              'Oth':1, 'WD':1,'CWD':2,\n",
    "                                              'Con':3, 'New':3})\n",
    "    \n",
    "df_full[\"nfSaleCondition\"] = df_full.SaleCondition.map({'AdjLand':1,\n",
    "                                                        'Abnorml':2,\n",
    "                                                        'Alloca':2,\n",
    "                                                        'Family':2,\n",
    "                                                        'Normal':3,\n",
    "                                                        'Partial':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"SalePrice\"]\n",
    "df_full.drop(\"LotAreaCut\", axis=1, inplace=True)\n",
    "df_full.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoScaler = MinMaxScaler()\n",
    "\n",
    "for col in cols3:\n",
    "    df_full[\"nf{}\".format(col)] = zoScaler.fit_transform(\n",
    "        df_full[[\"nf{}\".format(col)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols4 = [\"GrLivArea\", \"TotalHouse\"]\n",
    "for col in cols4:\n",
    "    df_full[\"log_{}\".format(col)] = np.log(df_full[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labelenc(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        lab=LabelEncoder()\n",
    "        X[\"YearBuilt\"] = lab.fit_transform(X[\"YearBuilt\"])\n",
    "        X[\"YearRemodAdd\"] = lab.fit_transform(X[\"YearRemodAdd\"])\n",
    "        X[\"GarageYrBlt\"] = lab.fit_transform(X[\"GarageYrBlt\"])\n",
    "        return X\n",
    "\n",
    "class skew_dummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,skew=1.2):\n",
    "        self.skew = skew\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        X_numeric=X.select_dtypes(exclude=[\"object\"])\n",
    "        skewness = X_numeric.apply(lambda x: skew(x))\n",
    "        skewness_features = skewness[abs(skewness) >= self.skew].index\n",
    "        X[skewness_features] = np.log1p(X[skewness_features])\n",
    "        X = pd.get_dummies(X)\n",
    "        return X\n",
    "\n",
    "rScaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_feature(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        \n",
    "        X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"]\n",
    "        X[\"+_TotalHouse_OverallQual\"] = X[\"TotalHouse\"] * X[\"OverallQual\"]\n",
    "        X[\"+_GrLivArea_OverallQual\"] = X[\"GrLivArea\"] * X[\"OverallQual\"]\n",
    "        X[\"+_nfMSZoning_TotalHouse\"] = X[\"nfMSZoning\"] * X[\"TotalHouse\"]\n",
    "        X[\"+_nfMSZoning_OverallQual\"] = X[\"nfMSZoning\"] + X[\"OverallQual\"]\n",
    "        X[\"+_nfMSZoning_YearBuilt\"] = X[\"nfMSZoning\"] + X[\"YearBuilt\"]\n",
    "        X[\"+_nfNeighborhood_TotalHouse\"] = X[\"nfNeighborhood\"] * X[\"TotalHouse\"]\n",
    "        X[\"+_nfNeighborhood_OverallQual\"] = X[\"nfNeighborhood\"] + X[\"OverallQual\"]\n",
    "        X[\"+_nfNeighborhood_YearBuilt\"] = X[\"nfNeighborhood\"] + X[\"YearBuilt\"]\n",
    "        X[\"+_BsmtFinSF1_OverallQual\"] = X[\"BsmtFinSF1\"] * X[\"OverallQual\"]\n",
    "        X[\"-_nfFunctional_TotalHouse\"] = X[\"nfFunctional\"] * X[\"TotalHouse\"]\n",
    "        X[\"-_nfFunctional_OverallQual\"] = X[\"nfFunctional\"] + X[\"OverallQual\"]\n",
    "        X[\"-_LotArea_OverallQual\"] = X[\"LotArea\"] * X[\"OverallQual\"]\n",
    "        X[\"-_TotalHouse_LotArea\"] = X[\"TotalHouse\"] + X[\"LotArea\"]\n",
    "        X[\"-_nfCondition1_TotalHouse\"] = X[\"nfCondition1\"] * X[\"TotalHouse\"]\n",
    "        X[\"-_nfCondition1_OverallQual\"] = X[\"nfCondition1\"] + X[\"OverallQual\"]\n",
    "        X[\"Bsmt\"] = X[\"BsmtFinSF1\"] + X[\"BsmtFinSF2\"] + X[\"BsmtUnfSF\"]\n",
    "        X[\"Rooms\"] = X[\"FullBath\"]+X[\"TotRmsAbvGrd\"]\n",
    "        X[\"PorchArea\"] = X[\"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n",
    "        X[\"TotalPlace\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\n",
    "            \"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n",
    "\n",
    "\n",
    "        X[\"+_log_TotalHouse_OverallQual\"] = X[\"log_TotalHouse\"] * X[\"OverallQual\"]\n",
    "        X[\"+_log_GrLivArea_OverallQual\"] = X[\"log_GrLivArea\"] * X[\"OverallQual\"]\n",
    "        X[\"+_nfMSZoning_log_TotalHouse\"] = X[\"nfMSZoning\"] * X[\"log_TotalHouse\"]\n",
    "        X[\"+_nfNeighborhood_log_TotalHouse\"] = X[\"nfNeighborhood\"] * X[\"log_TotalHouse\"]\n",
    "        X[\"-_nfFunctional_log_TotalHouse\"] = X[\"nfFunctional\"] * X[\"log_TotalHouse\"]\n",
    "        X[\"-_log_TotalHouse_LotArea\"] = X[\"log_TotalHouse\"] + X[\"LotArea\"]\n",
    "        X[\"-_nfCondition1_log_TotalHouse\"] = X[\"nfCondition1\"] * X[\"log_TotalHouse\"]\n",
    "\n",
    "\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('labenc', labelenc()),\n",
    "    ('add_feature', add_feature()),\n",
    "    ('skew_dummies', skew_dummies(skew=1.2)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_p = pipe.fit_transform(df_full)\n",
    "df_full_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = df_train.shape[0]\n",
    "X_train = df_full_p[:n_train]\n",
    "X_test = df_full_p[n_train:]\n",
    "\n",
    "X_train_sc = rScaler.fit(X_train).transform(X_train)\n",
    "y_log = np.log(y_train)\n",
    "X_test_sc = rScaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.001)\n",
    "lasso.fit(X_train_sc,y_log)\n",
    "\n",
    "FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_},\n",
    "                        index=df_full_p.columns)\n",
    "imp_lasso = FI_lasso[np.abs(FI_lasso[\"Feature Importance\"])>0.001].sort_values(\"Feature Importance\")\n",
    "print(\"important features in lasso: \",imp_lasso.shape)\n",
    "imp_lasso.plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` however if you try to find important features with Ridge, the shape will be much more ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9999, svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = pca.fit_transform(X_train_sc)\n",
    "X_test_sc = pca.transform(X_test_sc)\n",
    "X_train_sc.shape, X_test_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"dataset/X_train.csv\", X_train_sc, delimiter=\",\")\n",
    "np.savetxt(\"dataset/X_test.csv\", X_test_sc, delimiter=\",\")\n",
    "np.savetxt(\"dataset/y_train.csv\", y_train, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
