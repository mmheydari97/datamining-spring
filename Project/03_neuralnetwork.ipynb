{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./dataset/X_train.csv\", header=None)\n",
    "X_test = pd.read_csv(\"./dataset/X_test.csv\", header=None)\n",
    "y_train = pd.read_csv(\"./dataset/y_train.csv\", header=None)\n",
    "\n",
    "y_train_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=inp_size, kernel_initializer='normal',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1312 samples, validate on 146 samples\n",
      "Epoch 1/2000\n",
      "1312/1312 [==============================] - 1s 724us/step - loss: 17.3768 - val_loss: 1.9716\n",
      "Epoch 2/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 3.4754 - val_loss: 0.7308\n",
      "Epoch 3/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 3.2119 - val_loss: 2.5139\n",
      "Epoch 4/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 3.3043 - val_loss: 1.0391\n",
      "Epoch 5/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 2.6294 - val_loss: 0.8886\n",
      "Epoch 6/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 2.5887 - val_loss: 0.5761\n",
      "Epoch 7/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 3.0714 - val_loss: 1.3124\n",
      "Epoch 8/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 2.6440 - val_loss: 0.3693\n",
      "Epoch 9/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 2.7976 - val_loss: 1.3181\n",
      "Epoch 10/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 2.7089 - val_loss: 0.3584\n",
      "Epoch 11/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.8293 - val_loss: 0.6768\n",
      "Epoch 12/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 2.3573 - val_loss: 0.6765\n",
      "Epoch 13/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 2.3512 - val_loss: 0.4268\n",
      "Epoch 14/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 2.7730 - val_loss: 0.3774\n",
      "Epoch 15/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.5269 - val_loss: 2.2287\n",
      "Epoch 16/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 2.2022 - val_loss: 1.0655\n",
      "Epoch 17/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 2.1774 - val_loss: 1.4791\n",
      "Epoch 18/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.3448 - val_loss: 0.4491\n",
      "Epoch 19/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.8332 - val_loss: 1.2357\n",
      "Epoch 20/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.2502 - val_loss: 1.6186\n",
      "Epoch 21/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.1487 - val_loss: 0.4275\n",
      "Epoch 22/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 2.1759 - val_loss: 0.7879\n",
      "Epoch 23/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 2.0950 - val_loss: 1.6638\n",
      "Epoch 24/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.9441 - val_loss: 0.3016\n",
      "Epoch 25/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 2.1634 - val_loss: 1.0852\n",
      "Epoch 26/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 2.0267 - val_loss: 0.2699\n",
      "Epoch 27/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 2.1658 - val_loss: 0.7895\n",
      "Epoch 28/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 2.1328 - val_loss: 1.7322\n",
      "Epoch 29/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 2.3044 - val_loss: 0.4272\n",
      "Epoch 30/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 2.1045 - val_loss: 0.3457\n",
      "Epoch 31/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 1.8991 - val_loss: 0.2744\n",
      "Epoch 32/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 1.9663 - val_loss: 1.5141\n",
      "Epoch 33/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.7963 - val_loss: 0.2937\n",
      "Epoch 34/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 2.0970 - val_loss: 0.4562\n",
      "Epoch 35/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 2.1218 - val_loss: 0.8333\n",
      "Epoch 36/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 1.8863 - val_loss: 0.3708\n",
      "Epoch 37/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 2.0970 - val_loss: 0.4423\n",
      "Epoch 38/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 2.0768 - val_loss: 0.3568\n",
      "Epoch 39/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 1.9316 - val_loss: 0.4216\n",
      "Epoch 40/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 1.8406 - val_loss: 0.2799\n",
      "Epoch 41/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.7483 - val_loss: 0.2788\n",
      "Epoch 42/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.8953 - val_loss: 0.3373\n",
      "Epoch 43/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 2.0210 - val_loss: 0.2140\n",
      "Epoch 44/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.6122 - val_loss: 0.2292\n",
      "Epoch 45/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 1.8194 - val_loss: 0.9415\n",
      "Epoch 46/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.9293 - val_loss: 0.6724\n",
      "Epoch 47/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.7827 - val_loss: 0.3625\n",
      "Epoch 48/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 1.5696 - val_loss: 0.4735\n",
      "Epoch 49/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 1.9992 - val_loss: 0.4377\n",
      "Epoch 50/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 1.6679 - val_loss: 0.2226\n",
      "Epoch 51/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.7596 - val_loss: 0.2772\n",
      "Epoch 52/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.7890 - val_loss: 0.5639\n",
      "Epoch 53/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.9309 - val_loss: 0.3127\n",
      "Epoch 54/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 1.6563 - val_loss: 0.3814\n",
      "Epoch 55/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 1.4977 - val_loss: 0.2311\n",
      "Epoch 56/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.5786 - val_loss: 0.2387\n",
      "Epoch 57/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.5654 - val_loss: 0.3174\n",
      "Epoch 58/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 1.6485 - val_loss: 0.2120\n",
      "Epoch 59/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.7194 - val_loss: 0.5404\n",
      "Epoch 60/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.7555 - val_loss: 0.2022\n",
      "Epoch 61/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 1.5482 - val_loss: 1.4222\n",
      "Epoch 62/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 1.6810 - val_loss: 0.4945\n",
      "Epoch 63/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 1.7040 - val_loss: 0.1670\n",
      "Epoch 64/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 1.5293 - val_loss: 0.2195\n",
      "Epoch 65/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 1.5256 - val_loss: 0.3325\n",
      "Epoch 66/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.5233 - val_loss: 0.1833\n",
      "Epoch 67/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.7941 - val_loss: 0.1860\n",
      "Epoch 68/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.3530 - val_loss: 0.1903\n",
      "Epoch 69/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.4002 - val_loss: 0.2368\n",
      "Epoch 70/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.4896 - val_loss: 0.2323\n",
      "Epoch 71/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.5669 - val_loss: 0.4016\n",
      "Epoch 72/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.3616 - val_loss: 0.1843\n",
      "Epoch 73/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.6646 - val_loss: 0.6318\n",
      "Epoch 74/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.5009 - val_loss: 0.3841\n",
      "Epoch 75/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.4620 - val_loss: 0.1705\n",
      "Epoch 76/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.5462 - val_loss: 0.7251\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.4404 - val_loss: 0.1855\n",
      "Epoch 78/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.4453 - val_loss: 0.1640\n",
      "Epoch 79/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.4573 - val_loss: 0.3285\n",
      "Epoch 80/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.4899 - val_loss: 0.3976\n",
      "Epoch 81/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.3448 - val_loss: 0.7401\n",
      "Epoch 82/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.4475 - val_loss: 0.5111\n",
      "Epoch 83/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.4480 - val_loss: 0.3130\n",
      "Epoch 84/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.3254 - val_loss: 0.3658\n",
      "Epoch 85/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.3816 - val_loss: 0.4285\n",
      "Epoch 86/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 1.3355 - val_loss: 0.4502\n",
      "Epoch 87/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.4194 - val_loss: 0.1781\n",
      "Epoch 88/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.2819 - val_loss: 0.1480\n",
      "Epoch 89/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.3492 - val_loss: 0.5495\n",
      "Epoch 90/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.3826 - val_loss: 0.1529\n",
      "Epoch 91/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.3705 - val_loss: 0.1369\n",
      "Epoch 92/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.2605 - val_loss: 0.2403\n",
      "Epoch 93/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.3949 - val_loss: 0.4549\n",
      "Epoch 94/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.3276 - val_loss: 0.1291\n",
      "Epoch 95/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.2771 - val_loss: 0.4486\n",
      "Epoch 96/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.2080 - val_loss: 0.1847\n",
      "Epoch 97/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.2447 - val_loss: 0.1202\n",
      "Epoch 98/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.2542 - val_loss: 0.1313\n",
      "Epoch 99/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 1.2561 - val_loss: 0.1572\n",
      "Epoch 100/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.2206 - val_loss: 0.1679\n",
      "Epoch 101/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.2871 - val_loss: 0.1674\n",
      "Epoch 102/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.3253 - val_loss: 0.3814\n",
      "Epoch 103/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.0494 - val_loss: 0.2109\n",
      "Epoch 104/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.2345 - val_loss: 0.2063\n",
      "Epoch 105/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.1433 - val_loss: 0.2020\n",
      "Epoch 106/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 1.1601 - val_loss: 0.1557\n",
      "Epoch 107/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.1754 - val_loss: 0.5241\n",
      "Epoch 108/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.1561 - val_loss: 0.3944\n",
      "Epoch 109/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.1929 - val_loss: 0.1307\n",
      "Epoch 110/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.1162 - val_loss: 0.1102\n",
      "Epoch 111/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.2067 - val_loss: 0.2721\n",
      "Epoch 112/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.1608 - val_loss: 0.1702\n",
      "Epoch 113/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 1.0692 - val_loss: 0.2002\n",
      "Epoch 114/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.0923 - val_loss: 0.1911\n",
      "Epoch 115/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.1377 - val_loss: 0.1411\n",
      "Epoch 116/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.0878 - val_loss: 0.1561\n",
      "Epoch 117/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.0989 - val_loss: 0.2746\n",
      "Epoch 118/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 1.0348 - val_loss: 0.5238\n",
      "Epoch 119/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.1609 - val_loss: 0.1035\n",
      "Epoch 120/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.0558 - val_loss: 0.5664\n",
      "Epoch 121/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 1.1036 - val_loss: 0.3406\n",
      "Epoch 122/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 1.1090 - val_loss: 0.1446\n",
      "Epoch 123/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 1.0784 - val_loss: 0.2121\n",
      "Epoch 124/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 1.0163 - val_loss: 0.4402\n",
      "Epoch 125/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.9737 - val_loss: 0.1216\n",
      "Epoch 126/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.9866 - val_loss: 0.1843\n",
      "Epoch 127/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.0245 - val_loss: 0.2529\n",
      "Epoch 128/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 1.0684 - val_loss: 0.2105\n",
      "Epoch 129/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 1.0194 - val_loss: 0.2249\n",
      "Epoch 130/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.9993 - val_loss: 0.1126\n",
      "Epoch 131/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 1.0331 - val_loss: 0.0806\n",
      "Epoch 132/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.9474 - val_loss: 0.4542\n",
      "Epoch 133/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 1.0010 - val_loss: 0.1634\n",
      "Epoch 134/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.9758 - val_loss: 0.0644\n",
      "Epoch 135/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.9316 - val_loss: 0.2005\n",
      "Epoch 136/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.9143 - val_loss: 0.1098\n",
      "Epoch 137/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.9557 - val_loss: 0.1584\n",
      "Epoch 138/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.9689 - val_loss: 0.2136\n",
      "Epoch 139/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.8641 - val_loss: 0.2300\n",
      "Epoch 140/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.8812 - val_loss: 0.1314\n",
      "Epoch 141/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.8955 - val_loss: 0.1318\n",
      "Epoch 142/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.8796 - val_loss: 0.1887\n",
      "Epoch 143/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.9037 - val_loss: 0.0520\n",
      "Epoch 144/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8772 - val_loss: 0.1196\n",
      "Epoch 145/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.9208 - val_loss: 0.1179\n",
      "Epoch 146/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.8630 - val_loss: 0.0999\n",
      "Epoch 147/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.8790 - val_loss: 0.1054\n",
      "Epoch 148/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.8537 - val_loss: 0.0569\n",
      "Epoch 149/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8191 - val_loss: 0.1274\n",
      "Epoch 150/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8391 - val_loss: 0.1121\n",
      "Epoch 151/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8451 - val_loss: 0.0799\n",
      "Epoch 152/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8429 - val_loss: 0.1013\n",
      "Epoch 153/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7975 - val_loss: 0.2385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8103 - val_loss: 0.0968\n",
      "Epoch 155/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.8001 - val_loss: 0.1297\n",
      "Epoch 156/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.8218 - val_loss: 0.2097\n",
      "Epoch 157/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.8054 - val_loss: 0.1023\n",
      "Epoch 158/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7748 - val_loss: 0.1046\n",
      "Epoch 159/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7598 - val_loss: 0.0831\n",
      "Epoch 160/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7761 - val_loss: 0.0620\n",
      "Epoch 161/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7497 - val_loss: 0.0614\n",
      "Epoch 162/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.8143 - val_loss: 0.1003\n",
      "Epoch 163/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.6979 - val_loss: 0.0772\n",
      "Epoch 164/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.7777 - val_loss: 0.0655\n",
      "Epoch 165/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7758 - val_loss: 0.1310\n",
      "Epoch 166/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.7921 - val_loss: 0.0747\n",
      "Epoch 167/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7111 - val_loss: 0.0931\n",
      "Epoch 168/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.7605 - val_loss: 0.0431\n",
      "Epoch 169/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.7266 - val_loss: 0.0597\n",
      "Epoch 170/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.7592 - val_loss: 0.0680\n",
      "Epoch 171/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.7039 - val_loss: 0.0689\n",
      "Epoch 172/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.7099 - val_loss: 0.0549\n",
      "Epoch 173/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.6800 - val_loss: 0.0774\n",
      "Epoch 174/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.6921 - val_loss: 0.0758\n",
      "Epoch 175/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.6749 - val_loss: 0.0449\n",
      "Epoch 176/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.6419 - val_loss: 0.0411\n",
      "Epoch 177/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.6700 - val_loss: 0.0689\n",
      "Epoch 178/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.6602 - val_loss: 0.0707\n",
      "Epoch 179/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.6058 - val_loss: 0.0675\n",
      "Epoch 180/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.6030 - val_loss: 0.0703\n",
      "Epoch 181/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.7034 - val_loss: 0.0363\n",
      "Epoch 182/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.6187 - val_loss: 0.0370\n",
      "Epoch 183/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.6606 - val_loss: 0.0459\n",
      "Epoch 184/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.6258 - val_loss: 0.0564\n",
      "Epoch 185/2000\n",
      "1312/1312 [==============================] - 0s 110us/step - loss: 0.5852 - val_loss: 0.0459\n",
      "Epoch 186/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.6388 - val_loss: 0.0478\n",
      "Epoch 187/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.6044 - val_loss: 0.0375\n",
      "Epoch 188/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.6175 - val_loss: 0.0869\n",
      "Epoch 189/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5889 - val_loss: 0.0831\n",
      "Epoch 190/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5534 - val_loss: 0.0487\n",
      "Epoch 191/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5940 - val_loss: 0.0352\n",
      "Epoch 192/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.5320 - val_loss: 0.1228\n",
      "Epoch 193/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.5581 - val_loss: 0.0821\n",
      "Epoch 194/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.6206 - val_loss: 0.0790\n",
      "Epoch 195/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.5412 - val_loss: 0.0466\n",
      "Epoch 196/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5613 - val_loss: 0.0228\n",
      "Epoch 197/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.5595 - val_loss: 0.0288\n",
      "Epoch 198/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5554 - val_loss: 0.0228\n",
      "Epoch 199/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5414 - val_loss: 0.0649\n",
      "Epoch 200/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.5241 - val_loss: 0.0762\n",
      "Epoch 201/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.5062 - val_loss: 0.0436\n",
      "Epoch 202/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.5424 - val_loss: 0.0244\n",
      "Epoch 203/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.5226 - val_loss: 0.0272\n",
      "Epoch 204/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5216 - val_loss: 0.0381\n",
      "Epoch 205/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.5016 - val_loss: 0.0306\n",
      "Epoch 206/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.5150 - val_loss: 0.0261\n",
      "Epoch 207/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4915 - val_loss: 0.0244\n",
      "Epoch 208/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.4979 - val_loss: 0.0287\n",
      "Epoch 209/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.5289 - val_loss: 0.0245\n",
      "Epoch 210/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.5181 - val_loss: 0.0460\n",
      "Epoch 211/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.4558 - val_loss: 0.0256\n",
      "Epoch 212/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.4714 - val_loss: 0.0251\n",
      "Epoch 213/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.4694 - val_loss: 0.0265\n",
      "Epoch 214/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.4807 - val_loss: 0.0196\n",
      "Epoch 215/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.4700 - val_loss: 0.0218\n",
      "Epoch 216/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.4766 - val_loss: 0.0210\n",
      "Epoch 217/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.4518 - val_loss: 0.0233\n",
      "Epoch 218/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.4640 - val_loss: 0.0222\n",
      "Epoch 219/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.4688 - val_loss: 0.0505\n",
      "Epoch 220/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4545 - val_loss: 0.0210\n",
      "Epoch 221/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4740 - val_loss: 0.0432\n",
      "Epoch 222/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.4748 - val_loss: 0.0207\n",
      "Epoch 223/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.4803 - val_loss: 0.0215\n",
      "Epoch 224/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4401 - val_loss: 0.0394\n",
      "Epoch 225/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.4464 - val_loss: 0.0298\n",
      "Epoch 226/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.4393 - val_loss: 0.0261\n",
      "Epoch 227/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4220 - val_loss: 0.0258\n",
      "Epoch 228/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.4396 - val_loss: 0.0202\n",
      "Epoch 229/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.3932 - val_loss: 0.0180\n",
      "Epoch 230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.4131 - val_loss: 0.0209\n",
      "Epoch 231/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.4201 - val_loss: 0.0218\n",
      "Epoch 232/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.4214 - val_loss: 0.0254\n",
      "Epoch 233/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.4273 - val_loss: 0.0220\n",
      "Epoch 234/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.3789 - val_loss: 0.0366\n",
      "Epoch 235/2000\n",
      "1312/1312 [==============================] - 0s 111us/step - loss: 0.4045 - val_loss: 0.0386\n",
      "Epoch 236/2000\n",
      "1312/1312 [==============================] - 0s 115us/step - loss: 0.3630 - val_loss: 0.0197\n",
      "Epoch 237/2000\n",
      "1312/1312 [==============================] - 0s 111us/step - loss: 0.3814 - val_loss: 0.0217\n",
      "Epoch 238/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.3760 - val_loss: 0.0211\n",
      "Epoch 239/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.3626 - val_loss: 0.0344\n",
      "Epoch 240/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.3295 - val_loss: 0.0274\n",
      "Epoch 241/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.3415 - val_loss: 0.1597\n",
      "Epoch 242/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.3722 - val_loss: 0.0423\n",
      "Epoch 243/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.3489 - val_loss: 0.0409\n",
      "Epoch 244/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.3366 - val_loss: 0.0297\n",
      "Epoch 245/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.3359 - val_loss: 0.0210\n",
      "Epoch 246/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.3067 - val_loss: 0.0200\n",
      "Epoch 247/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.3314 - val_loss: 0.0207\n",
      "Epoch 248/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.3458 - val_loss: 0.0195\n",
      "Epoch 249/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.3207 - val_loss: 0.0239\n",
      "Epoch 250/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.3081 - val_loss: 0.0275\n",
      "Epoch 251/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.3291 - val_loss: 0.0245\n",
      "Epoch 252/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.3290 - val_loss: 0.0242\n",
      "Epoch 253/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.3377 - val_loss: 0.0356\n",
      "Epoch 254/2000\n",
      "1312/1312 [==============================] - 0s 116us/step - loss: 0.3061 - val_loss: 0.0194\n",
      "Epoch 255/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.3227 - val_loss: 0.0205\n",
      "Epoch 256/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.3319 - val_loss: 0.0187\n",
      "Epoch 257/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.2995 - val_loss: 0.0166\n",
      "Epoch 258/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.3208 - val_loss: 0.0258\n",
      "Epoch 259/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.3203 - val_loss: 0.0219\n",
      "Epoch 260/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.2849 - val_loss: 0.0270\n",
      "Epoch 261/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.2890 - val_loss: 0.0426\n",
      "Epoch 262/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.2877 - val_loss: 0.0172\n",
      "Epoch 263/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.2794 - val_loss: 0.0411\n",
      "Epoch 264/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.2950 - val_loss: 0.0365\n",
      "Epoch 265/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.2810 - val_loss: 0.0180\n",
      "Epoch 266/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.2770 - val_loss: 0.0467\n",
      "Epoch 267/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.2765 - val_loss: 0.0256\n",
      "Epoch 268/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.2814 - val_loss: 0.0234\n",
      "Epoch 269/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2830 - val_loss: 0.0187\n",
      "Epoch 270/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.2621 - val_loss: 0.0210\n",
      "Epoch 271/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2644 - val_loss: 0.0183\n",
      "Epoch 272/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2436 - val_loss: 0.0218\n",
      "Epoch 273/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2434 - val_loss: 0.0213\n",
      "Epoch 274/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.2555 - val_loss: 0.0199\n",
      "Epoch 275/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2393 - val_loss: 0.0271\n",
      "Epoch 276/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2321 - val_loss: 0.0198\n",
      "Epoch 277/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2399 - val_loss: 0.0228\n",
      "Epoch 278/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.2433 - val_loss: 0.0294\n",
      "Epoch 279/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2216 - val_loss: 0.0193\n",
      "Epoch 280/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.2440 - val_loss: 0.0220\n",
      "Epoch 281/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.2367 - val_loss: 0.0224\n",
      "Epoch 282/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2220 - val_loss: 0.0255\n",
      "Epoch 283/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.2198 - val_loss: 0.0354\n",
      "Epoch 284/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2478 - val_loss: 0.0192\n",
      "Epoch 285/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.2235 - val_loss: 0.0291\n",
      "Epoch 286/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2299 - val_loss: 0.0251\n",
      "Epoch 287/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2183 - val_loss: 0.0207\n",
      "Epoch 288/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2220 - val_loss: 0.0420\n",
      "Epoch 289/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.2173 - val_loss: 0.0175\n",
      "Epoch 290/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2276 - val_loss: 0.0218\n",
      "Epoch 291/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1987 - val_loss: 0.0262\n",
      "Epoch 292/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2279 - val_loss: 0.0197\n",
      "Epoch 293/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2162 - val_loss: 0.0248\n",
      "Epoch 294/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2250 - val_loss: 0.0225\n",
      "Epoch 295/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2137 - val_loss: 0.0263\n",
      "Epoch 296/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.2058 - val_loss: 0.0237\n",
      "Epoch 297/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.2050 - val_loss: 0.0227\n",
      "Epoch 298/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.2111 - val_loss: 0.0270\n",
      "Epoch 299/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.2148 - val_loss: 0.0241\n",
      "Epoch 300/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.2030 - val_loss: 0.0354\n",
      "Epoch 301/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.2054 - val_loss: 0.0210\n",
      "Epoch 302/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1843 - val_loss: 0.0282\n",
      "Epoch 303/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.2015 - val_loss: 0.0278\n",
      "Epoch 304/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1962 - val_loss: 0.0435\n",
      "Epoch 305/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2010 - val_loss: 0.0261\n",
      "Epoch 306/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1962 - val_loss: 0.0215\n",
      "Epoch 307/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.2038 - val_loss: 0.0237\n",
      "Epoch 308/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1845 - val_loss: 0.0253\n",
      "Epoch 309/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1796 - val_loss: 0.0270\n",
      "Epoch 310/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1916 - val_loss: 0.0505\n",
      "Epoch 311/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1878 - val_loss: 0.0198\n",
      "Epoch 312/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1745 - val_loss: 0.0165\n",
      "Epoch 313/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1820 - val_loss: 0.0204\n",
      "Epoch 314/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1809 - val_loss: 0.0192\n",
      "Epoch 315/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1754 - val_loss: 0.0188\n",
      "Epoch 316/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1667 - val_loss: 0.0173\n",
      "Epoch 317/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1665 - val_loss: 0.0263\n",
      "Epoch 318/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1777 - val_loss: 0.0179\n",
      "Epoch 319/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1663 - val_loss: 0.0182\n",
      "Epoch 320/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1748 - val_loss: 0.0223\n",
      "Epoch 321/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1666 - val_loss: 0.0202\n",
      "Epoch 322/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1696 - val_loss: 0.0176\n",
      "Epoch 323/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1691 - val_loss: 0.0200\n",
      "Epoch 324/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.1639 - val_loss: 0.0238\n",
      "Epoch 325/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.1582 - val_loss: 0.0165\n",
      "Epoch 326/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.1606 - val_loss: 0.0199\n",
      "Epoch 327/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1673 - val_loss: 0.0184\n",
      "Epoch 328/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.1545 - val_loss: 0.0195\n",
      "Epoch 329/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1507 - val_loss: 0.0207\n",
      "Epoch 330/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1475 - val_loss: 0.0183\n",
      "Epoch 331/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.1526 - val_loss: 0.0169\n",
      "Epoch 332/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1449 - val_loss: 0.0178\n",
      "Epoch 333/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1609 - val_loss: 0.0195\n",
      "Epoch 334/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1518 - val_loss: 0.0228\n",
      "Epoch 335/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1533 - val_loss: 0.0187\n",
      "Epoch 336/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1489 - val_loss: 0.0200\n",
      "Epoch 337/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.1451 - val_loss: 0.0166\n",
      "Epoch 338/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.1440 - val_loss: 0.0197\n",
      "Epoch 339/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1382 - val_loss: 0.0229\n",
      "Epoch 340/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1386 - val_loss: 0.0238\n",
      "Epoch 341/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.1446 - val_loss: 0.0205\n",
      "Epoch 342/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1345 - val_loss: 0.0288\n",
      "Epoch 343/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.1406 - val_loss: 0.0220\n",
      "Epoch 344/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.1431 - val_loss: 0.0198\n",
      "Epoch 345/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.1272 - val_loss: 0.0180\n",
      "Epoch 346/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.1266 - val_loss: 0.0178\n",
      "Epoch 347/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.1306 - val_loss: 0.0254\n",
      "Epoch 348/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1344 - val_loss: 0.0187\n",
      "Epoch 349/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1229 - val_loss: 0.0177\n",
      "Epoch 350/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1307 - val_loss: 0.0165\n",
      "Epoch 351/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.1212 - val_loss: 0.0175\n",
      "Epoch 352/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.1230 - val_loss: 0.0175\n",
      "Epoch 353/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.1188 - val_loss: 0.0213\n",
      "Epoch 354/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.1207 - val_loss: 0.0178\n",
      "Epoch 355/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.1212 - val_loss: 0.0178\n",
      "Epoch 356/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.1196 - val_loss: 0.0194\n",
      "Epoch 357/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.1169 - val_loss: 0.0334\n",
      "Epoch 358/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1155 - val_loss: 0.0205\n",
      "Epoch 359/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1197 - val_loss: 0.0227\n",
      "Epoch 360/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1119 - val_loss: 0.0181\n",
      "Epoch 361/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1023 - val_loss: 0.0189\n",
      "Epoch 362/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.1098 - val_loss: 0.0220\n",
      "Epoch 363/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.1075 - val_loss: 0.0173\n",
      "Epoch 364/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.1017 - val_loss: 0.0163\n",
      "Epoch 365/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1018 - val_loss: 0.0307\n",
      "Epoch 366/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.1115 - val_loss: 0.0199\n",
      "Epoch 367/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.1111 - val_loss: 0.0193\n",
      "Epoch 368/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1022 - val_loss: 0.0188\n",
      "Epoch 369/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.1026 - val_loss: 0.0237\n",
      "Epoch 370/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.1029 - val_loss: 0.0265\n",
      "Epoch 371/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0996 - val_loss: 0.0198\n",
      "Epoch 372/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0974 - val_loss: 0.0213\n",
      "Epoch 373/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0913 - val_loss: 0.0205\n",
      "Epoch 374/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0940 - val_loss: 0.0226\n",
      "Epoch 375/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0924 - val_loss: 0.0187\n",
      "Epoch 376/2000\n",
      "1312/1312 [==============================] - 0s 120us/step - loss: 0.0983 - val_loss: 0.0172\n",
      "Epoch 377/2000\n",
      "1312/1312 [==============================] - 0s 127us/step - loss: 0.1022 - val_loss: 0.0196\n",
      "Epoch 378/2000\n",
      "1312/1312 [==============================] - 0s 112us/step - loss: 0.0927 - val_loss: 0.0176\n",
      "Epoch 379/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.0924 - val_loss: 0.0231\n",
      "Epoch 380/2000\n",
      "1312/1312 [==============================] - 0s 120us/step - loss: 0.0892 - val_loss: 0.0187\n",
      "Epoch 381/2000\n",
      "1312/1312 [==============================] - 0s 115us/step - loss: 0.0825 - val_loss: 0.0240\n",
      "Epoch 382/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0840 - val_loss: 0.0216\n",
      "Epoch 383/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0844 - val_loss: 0.0169\n",
      "Epoch 384/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0882 - val_loss: 0.0223\n",
      "Epoch 385/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0870 - val_loss: 0.0219\n",
      "Epoch 386/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0802 - val_loss: 0.0211\n",
      "Epoch 387/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0790 - val_loss: 0.0188\n",
      "Epoch 388/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0836 - val_loss: 0.0178\n",
      "Epoch 389/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0844 - val_loss: 0.0197\n",
      "Epoch 390/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0871 - val_loss: 0.0166\n",
      "Epoch 391/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0768 - val_loss: 0.0305\n",
      "Epoch 392/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0869 - val_loss: 0.0191\n",
      "Epoch 393/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0844 - val_loss: 0.0200\n",
      "Epoch 394/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0799 - val_loss: 0.0201\n",
      "Epoch 395/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0816 - val_loss: 0.0200\n",
      "Epoch 396/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0728 - val_loss: 0.0207\n",
      "Epoch 397/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0767 - val_loss: 0.0234\n",
      "Epoch 398/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0736 - val_loss: 0.0214\n",
      "Epoch 399/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0700 - val_loss: 0.0195\n",
      "Epoch 400/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0676 - val_loss: 0.0234\n",
      "Epoch 401/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0661 - val_loss: 0.0194\n",
      "Epoch 402/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0183\n",
      "Epoch 403/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0685 - val_loss: 0.0213\n",
      "Epoch 404/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0696 - val_loss: 0.0217\n",
      "Epoch 405/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0677 - val_loss: 0.0215\n",
      "Epoch 406/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0644 - val_loss: 0.0248\n",
      "Epoch 407/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0617 - val_loss: 0.0183\n",
      "Epoch 408/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0614 - val_loss: 0.0188\n",
      "Epoch 409/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0633 - val_loss: 0.0186\n",
      "Epoch 410/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0162\n",
      "Epoch 411/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0628 - val_loss: 0.0166\n",
      "Epoch 412/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0548 - val_loss: 0.0163\n",
      "Epoch 413/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0609 - val_loss: 0.0211\n",
      "Epoch 414/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0615 - val_loss: 0.0178\n",
      "Epoch 415/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0574 - val_loss: 0.0178\n",
      "Epoch 416/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0549 - val_loss: 0.0200\n",
      "Epoch 417/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0563 - val_loss: 0.0171\n",
      "Epoch 418/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0559 - val_loss: 0.0207\n",
      "Epoch 419/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0512 - val_loss: 0.0172\n",
      "Epoch 420/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0527 - val_loss: 0.0178\n",
      "Epoch 421/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0505 - val_loss: 0.0191\n",
      "Epoch 422/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0561 - val_loss: 0.0165\n",
      "Epoch 423/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0489 - val_loss: 0.0180\n",
      "Epoch 424/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0527 - val_loss: 0.0186\n",
      "Epoch 425/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0176\n",
      "Epoch 426/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0510 - val_loss: 0.0192\n",
      "Epoch 427/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0526 - val_loss: 0.0215\n",
      "Epoch 428/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0474 - val_loss: 0.0203\n",
      "Epoch 429/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0485 - val_loss: 0.0199\n",
      "Epoch 430/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0439 - val_loss: 0.0214\n",
      "Epoch 431/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0441 - val_loss: 0.0199\n",
      "Epoch 432/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0477 - val_loss: 0.0184\n",
      "Epoch 433/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0461 - val_loss: 0.0175\n",
      "Epoch 434/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0423 - val_loss: 0.0207\n",
      "Epoch 435/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0462 - val_loss: 0.0168\n",
      "Epoch 436/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0421 - val_loss: 0.0182\n",
      "Epoch 437/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0384 - val_loss: 0.0207\n",
      "Epoch 438/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0443 - val_loss: 0.0183\n",
      "Epoch 439/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0441 - val_loss: 0.0241\n",
      "Epoch 440/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0399 - val_loss: 0.0185\n",
      "Epoch 441/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0383 - val_loss: 0.0180\n",
      "Epoch 442/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0374 - val_loss: 0.0198\n",
      "Epoch 443/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0403 - val_loss: 0.0175\n",
      "Epoch 444/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0391 - val_loss: 0.0170\n",
      "Epoch 445/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0400 - val_loss: 0.0166\n",
      "Epoch 446/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0363 - val_loss: 0.0169\n",
      "Epoch 447/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0359 - val_loss: 0.0176\n",
      "Epoch 448/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0339 - val_loss: 0.0182\n",
      "Epoch 449/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0362 - val_loss: 0.0178\n",
      "Epoch 450/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0359 - val_loss: 0.0181\n",
      "Epoch 451/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0344 - val_loss: 0.0195\n",
      "Epoch 452/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0356 - val_loss: 0.0167\n",
      "Epoch 453/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0319 - val_loss: 0.0207\n",
      "Epoch 454/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0339 - val_loss: 0.0174\n",
      "Epoch 455/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0303 - val_loss: 0.0167\n",
      "Epoch 456/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0336 - val_loss: 0.0180\n",
      "Epoch 457/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0291 - val_loss: 0.0187\n",
      "Epoch 458/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0302 - val_loss: 0.0176\n",
      "Epoch 459/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0313 - val_loss: 0.0179\n",
      "Epoch 460/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0294 - val_loss: 0.0167\n",
      "Epoch 461/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0325 - val_loss: 0.0163\n",
      "Epoch 462/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0276 - val_loss: 0.0188\n",
      "Epoch 463/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0286 - val_loss: 0.0181\n",
      "Epoch 464/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0282 - val_loss: 0.0212\n",
      "Epoch 465/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0265 - val_loss: 0.0216\n",
      "Epoch 466/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0253 - val_loss: 0.0184\n",
      "Epoch 467/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0263 - val_loss: 0.0189\n",
      "Epoch 468/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0261 - val_loss: 0.0201\n",
      "Epoch 469/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0254 - val_loss: 0.0175\n",
      "Epoch 470/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0250 - val_loss: 0.0178\n",
      "Epoch 471/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0251 - val_loss: 0.0169\n",
      "Epoch 472/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0249 - val_loss: 0.0170\n",
      "Epoch 473/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0237 - val_loss: 0.0191\n",
      "Epoch 474/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0250 - val_loss: 0.0182\n",
      "Epoch 475/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0214 - val_loss: 0.0192\n",
      "Epoch 476/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0230 - val_loss: 0.0172\n",
      "Epoch 477/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0220 - val_loss: 0.0190\n",
      "Epoch 478/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0217 - val_loss: 0.0209\n",
      "Epoch 479/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0193 - val_loss: 0.0171\n",
      "Epoch 480/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 481/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 482/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0203 - val_loss: 0.0183\n",
      "Epoch 483/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 484/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0194 - val_loss: 0.0178\n",
      "Epoch 485/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0204 - val_loss: 0.0173\n",
      "Epoch 486/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0182 - val_loss: 0.0159\n",
      "Epoch 487/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0195 - val_loss: 0.0212\n",
      "Epoch 488/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 489/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0179 - val_loss: 0.0196\n",
      "Epoch 490/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0156 - val_loss: 0.0182\n",
      "Epoch 491/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0174 - val_loss: 0.0192\n",
      "Epoch 492/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0168 - val_loss: 0.0190\n",
      "Epoch 493/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 494/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0160 - val_loss: 0.0206\n",
      "Epoch 495/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0143 - val_loss: 0.0184\n",
      "Epoch 496/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 497/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0161 - val_loss: 0.0183\n",
      "Epoch 498/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 499/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 500/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0145 - val_loss: 0.0192\n",
      "Epoch 501/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0143 - val_loss: 0.0176\n",
      "Epoch 502/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0145 - val_loss: 0.0184\n",
      "Epoch 503/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0143 - val_loss: 0.0184\n",
      "Epoch 504/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0149 - val_loss: 0.0176\n",
      "Epoch 505/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0128 - val_loss: 0.0185\n",
      "Epoch 506/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0130 - val_loss: 0.0181\n",
      "Epoch 507/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 508/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0127 - val_loss: 0.0172\n",
      "Epoch 509/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0125 - val_loss: 0.0197\n",
      "Epoch 510/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 511/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0123 - val_loss: 0.0181\n",
      "Epoch 512/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 513/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0113 - val_loss: 0.0169\n",
      "Epoch 514/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 515/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0117 - val_loss: 0.0180\n",
      "Epoch 516/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0107 - val_loss: 0.0167\n",
      "Epoch 517/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0122 - val_loss: 0.0182\n",
      "Epoch 518/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0122 - val_loss: 0.0185\n",
      "Epoch 519/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0101 - val_loss: 0.0176\n",
      "Epoch 520/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0103 - val_loss: 0.0183\n",
      "Epoch 521/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0114 - val_loss: 0.0174\n",
      "Epoch 522/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0106 - val_loss: 0.0168\n",
      "Epoch 523/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 524/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0099 - val_loss: 0.0171\n",
      "Epoch 525/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0105 - val_loss: 0.0217\n",
      "Epoch 526/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0107 - val_loss: 0.0163\n",
      "Epoch 527/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0098 - val_loss: 0.0200\n",
      "Epoch 528/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0097 - val_loss: 0.0156\n",
      "Epoch 529/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0087 - val_loss: 0.0184\n",
      "Epoch 530/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0093 - val_loss: 0.0169\n",
      "Epoch 531/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0094 - val_loss: 0.0168\n",
      "Epoch 532/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0094 - val_loss: 0.0193\n",
      "Epoch 533/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0085 - val_loss: 0.0182\n",
      "Epoch 534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0102 - val_loss: 0.0191\n",
      "Epoch 535/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0101 - val_loss: 0.0175\n",
      "Epoch 536/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0090 - val_loss: 0.0163\n",
      "Epoch 537/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0088 - val_loss: 0.0180\n",
      "Epoch 538/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0080 - val_loss: 0.0166\n",
      "Epoch 539/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0084 - val_loss: 0.0170\n",
      "Epoch 540/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0083 - val_loss: 0.0167\n",
      "Epoch 541/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0090 - val_loss: 0.0173\n",
      "Epoch 542/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 543/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0083 - val_loss: 0.0176\n",
      "Epoch 544/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0085 - val_loss: 0.0180\n",
      "Epoch 545/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 546/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0088 - val_loss: 0.0171\n",
      "Epoch 547/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0075 - val_loss: 0.0167\n",
      "Epoch 548/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0084 - val_loss: 0.0195\n",
      "Epoch 549/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0084 - val_loss: 0.0165\n",
      "Epoch 550/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0078 - val_loss: 0.0175\n",
      "Epoch 551/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0090 - val_loss: 0.0191\n",
      "Epoch 552/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0083 - val_loss: 0.0174\n",
      "Epoch 553/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0073 - val_loss: 0.0170\n",
      "Epoch 554/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0178\n",
      "Epoch 555/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0083 - val_loss: 0.0168\n",
      "Epoch 556/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 557/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0087 - val_loss: 0.0183\n",
      "Epoch 558/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0071 - val_loss: 0.0217\n",
      "Epoch 559/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0081 - val_loss: 0.0167\n",
      "Epoch 560/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0079 - val_loss: 0.0183\n",
      "Epoch 561/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0079 - val_loss: 0.0174\n",
      "Epoch 562/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0071 - val_loss: 0.0160\n",
      "Epoch 563/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0072 - val_loss: 0.0157\n",
      "Epoch 564/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0067 - val_loss: 0.0210\n",
      "Epoch 565/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0082 - val_loss: 0.0164\n",
      "Epoch 566/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0087 - val_loss: 0.0187\n",
      "Epoch 567/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0072 - val_loss: 0.0174\n",
      "Epoch 568/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0078 - val_loss: 0.0185\n",
      "Epoch 569/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0088 - val_loss: 0.0200\n",
      "Epoch 570/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0089 - val_loss: 0.0188\n",
      "Epoch 571/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 572/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0073 - val_loss: 0.0186\n",
      "Epoch 573/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0065 - val_loss: 0.0173\n",
      "Epoch 574/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0074 - val_loss: 0.0183\n",
      "Epoch 575/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0066 - val_loss: 0.0189\n",
      "Epoch 576/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0074 - val_loss: 0.0175\n",
      "Epoch 577/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0083 - val_loss: 0.0193\n",
      "Epoch 578/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0080 - val_loss: 0.0193\n",
      "Epoch 579/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0071 - val_loss: 0.0181\n",
      "Epoch 580/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0067 - val_loss: 0.0192\n",
      "Epoch 581/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0066 - val_loss: 0.0172\n",
      "Epoch 582/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0063 - val_loss: 0.0176\n",
      "Epoch 583/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0061 - val_loss: 0.0198\n",
      "Epoch 584/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0070 - val_loss: 0.0189\n",
      "Epoch 585/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0075 - val_loss: 0.0212\n",
      "Epoch 586/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0067 - val_loss: 0.0187\n",
      "Epoch 587/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0064 - val_loss: 0.0190\n",
      "Epoch 588/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0077 - val_loss: 0.0183\n",
      "Epoch 589/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0071 - val_loss: 0.0183\n",
      "Epoch 590/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0069 - val_loss: 0.0172\n",
      "Epoch 591/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0074 - val_loss: 0.0214\n",
      "Epoch 592/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0075 - val_loss: 0.0177\n",
      "Epoch 593/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0059 - val_loss: 0.0208\n",
      "Epoch 594/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0075 - val_loss: 0.0171\n",
      "Epoch 595/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0167\n",
      "Epoch 596/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0080 - val_loss: 0.0200\n",
      "Epoch 597/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0067 - val_loss: 0.0175\n",
      "Epoch 598/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0172\n",
      "Epoch 599/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0071 - val_loss: 0.0171\n",
      "Epoch 600/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0070 - val_loss: 0.0204\n",
      "Epoch 601/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 602/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0068 - val_loss: 0.0192\n",
      "Epoch 603/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0065 - val_loss: 0.0182\n",
      "Epoch 604/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0069 - val_loss: 0.0175\n",
      "Epoch 605/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0075 - val_loss: 0.0185\n",
      "Epoch 606/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0071 - val_loss: 0.0173\n",
      "Epoch 607/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0082 - val_loss: 0.0179\n",
      "Epoch 608/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0068 - val_loss: 0.0184\n",
      "Epoch 609/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0071 - val_loss: 0.0188\n",
      "Epoch 610/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0063 - val_loss: 0.0204\n",
      "Epoch 611/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0059 - val_loss: 0.0183\n",
      "Epoch 612/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0179\n",
      "Epoch 613/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 614/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0058 - val_loss: 0.0167\n",
      "Epoch 615/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0062 - val_loss: 0.0178\n",
      "Epoch 616/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0056 - val_loss: 0.0182\n",
      "Epoch 617/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0186\n",
      "Epoch 618/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0066 - val_loss: 0.0182\n",
      "Epoch 619/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0186\n",
      "Epoch 620/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0075 - val_loss: 0.0167\n",
      "Epoch 621/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 622/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0068 - val_loss: 0.0196\n",
      "Epoch 623/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0060 - val_loss: 0.0192\n",
      "Epoch 624/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0063 - val_loss: 0.0195\n",
      "Epoch 625/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0206\n",
      "Epoch 626/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0059 - val_loss: 0.0189\n",
      "Epoch 627/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0074 - val_loss: 0.0205\n",
      "Epoch 628/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0186\n",
      "Epoch 629/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0077 - val_loss: 0.0174\n",
      "Epoch 630/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0073 - val_loss: 0.0198\n",
      "Epoch 631/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0064 - val_loss: 0.0181\n",
      "Epoch 632/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0053 - val_loss: 0.0182\n",
      "Epoch 633/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 634/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0199\n",
      "Epoch 635/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 636/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 637/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0067 - val_loss: 0.0184\n",
      "Epoch 638/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0199\n",
      "Epoch 639/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0182\n",
      "Epoch 640/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0070 - val_loss: 0.0161\n",
      "Epoch 641/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0175\n",
      "Epoch 642/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0167\n",
      "Epoch 643/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0060 - val_loss: 0.0185\n",
      "Epoch 644/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 645/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0169\n",
      "Epoch 646/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0065 - val_loss: 0.0169\n",
      "Epoch 647/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0068 - val_loss: 0.0174\n",
      "Epoch 648/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0064 - val_loss: 0.0189\n",
      "Epoch 649/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0060 - val_loss: 0.0186\n",
      "Epoch 650/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0060 - val_loss: 0.0172\n",
      "Epoch 651/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0062 - val_loss: 0.0176\n",
      "Epoch 652/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0057 - val_loss: 0.0174\n",
      "Epoch 653/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0057 - val_loss: 0.0183\n",
      "Epoch 654/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0173\n",
      "Epoch 655/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0064 - val_loss: 0.0180\n",
      "Epoch 656/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0076 - val_loss: 0.0169\n",
      "Epoch 657/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0056 - val_loss: 0.0175\n",
      "Epoch 658/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0065 - val_loss: 0.0186\n",
      "Epoch 659/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0197\n",
      "Epoch 660/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0063 - val_loss: 0.0190\n",
      "Epoch 661/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0178\n",
      "Epoch 662/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0056 - val_loss: 0.0200\n",
      "Epoch 663/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0059 - val_loss: 0.0189\n",
      "Epoch 664/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0162\n",
      "Epoch 665/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0070 - val_loss: 0.0179\n",
      "Epoch 666/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0061 - val_loss: 0.0185\n",
      "Epoch 667/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0178\n",
      "Epoch 668/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0075 - val_loss: 0.0183\n",
      "Epoch 669/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0072 - val_loss: 0.0180\n",
      "Epoch 670/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0056 - val_loss: 0.0176\n",
      "Epoch 671/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0058 - val_loss: 0.0190\n",
      "Epoch 672/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0061 - val_loss: 0.0194\n",
      "Epoch 673/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0057 - val_loss: 0.0183\n",
      "Epoch 674/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0185\n",
      "Epoch 675/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0060 - val_loss: 0.0185\n",
      "Epoch 676/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0059 - val_loss: 0.0172\n",
      "Epoch 677/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0192\n",
      "Epoch 678/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0059 - val_loss: 0.0174\n",
      "Epoch 679/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0070 - val_loss: 0.0214\n",
      "Epoch 680/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0066 - val_loss: 0.0188\n",
      "Epoch 681/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0055 - val_loss: 0.0174\n",
      "Epoch 682/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0064 - val_loss: 0.0183\n",
      "Epoch 683/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0059 - val_loss: 0.0186\n",
      "Epoch 684/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0053 - val_loss: 0.0200\n",
      "Epoch 685/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 686/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 131us/step - loss: 0.0065 - val_loss: 0.0190\n",
      "Epoch 687/2000\n",
      "1312/1312 [==============================] - 0s 122us/step - loss: 0.0068 - val_loss: 0.0182\n",
      "Epoch 688/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0201\n",
      "Epoch 689/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0082 - val_loss: 0.0183\n",
      "Epoch 690/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0064 - val_loss: 0.0189\n",
      "Epoch 691/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0190\n",
      "Epoch 692/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0198\n",
      "Epoch 693/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0058 - val_loss: 0.0187\n",
      "Epoch 694/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0072 - val_loss: 0.0195\n",
      "Epoch 695/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0062 - val_loss: 0.0184\n",
      "Epoch 696/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0066 - val_loss: 0.0183\n",
      "Epoch 697/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0060 - val_loss: 0.0205\n",
      "Epoch 698/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0171\n",
      "Epoch 699/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0067 - val_loss: 0.0175\n",
      "Epoch 700/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0070 - val_loss: 0.0170\n",
      "Epoch 701/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0186\n",
      "Epoch 702/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0057 - val_loss: 0.0170\n",
      "Epoch 703/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0058 - val_loss: 0.0205\n",
      "Epoch 704/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0064 - val_loss: 0.0192\n",
      "Epoch 705/2000\n",
      "1312/1312 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0172\n",
      "Epoch 706/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0056 - val_loss: 0.0182\n",
      "Epoch 707/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0054 - val_loss: 0.0178\n",
      "Epoch 708/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0162\n",
      "Epoch 709/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0195\n",
      "Epoch 710/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0067 - val_loss: 0.0174\n",
      "Epoch 711/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0055 - val_loss: 0.0171\n",
      "Epoch 712/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0067 - val_loss: 0.0172\n",
      "Epoch 713/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 714/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0164\n",
      "Epoch 715/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0062 - val_loss: 0.0178\n",
      "Epoch 716/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0183\n",
      "Epoch 717/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0058 - val_loss: 0.0195\n",
      "Epoch 718/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0182\n",
      "Epoch 719/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0066 - val_loss: 0.0171\n",
      "Epoch 720/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0172\n",
      "Epoch 721/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0066 - val_loss: 0.0211\n",
      "Epoch 722/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0068 - val_loss: 0.0183\n",
      "Epoch 723/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0063 - val_loss: 0.0184\n",
      "Epoch 724/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0063 - val_loss: 0.0193\n",
      "Epoch 725/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0058 - val_loss: 0.0189\n",
      "Epoch 726/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0184\n",
      "Epoch 727/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0068 - val_loss: 0.0190\n",
      "Epoch 728/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0187\n",
      "Epoch 729/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0177\n",
      "Epoch 730/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0176\n",
      "Epoch 731/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0185\n",
      "Epoch 732/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0068 - val_loss: 0.0187\n",
      "Epoch 733/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0063 - val_loss: 0.0207\n",
      "Epoch 734/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0068 - val_loss: 0.0198\n",
      "Epoch 735/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0073 - val_loss: 0.0200\n",
      "Epoch 736/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0059 - val_loss: 0.0182\n",
      "Epoch 737/2000\n",
      "1312/1312 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0192\n",
      "Epoch 738/2000\n",
      "1312/1312 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0176\n",
      "Epoch 739/2000\n",
      "1312/1312 [==============================] - 0s 108us/step - loss: 0.0057 - val_loss: 0.0169\n",
      "Epoch 740/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0061 - val_loss: 0.0175\n",
      "Epoch 741/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0059 - val_loss: 0.0177\n",
      "Epoch 742/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0055 - val_loss: 0.0166\n",
      "Epoch 743/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0067 - val_loss: 0.0213\n",
      "Epoch 744/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0070 - val_loss: 0.0164\n",
      "Epoch 745/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0067 - val_loss: 0.0166\n",
      "Epoch 746/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0057 - val_loss: 0.0199\n",
      "Epoch 747/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0060 - val_loss: 0.0175\n",
      "Epoch 748/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0065 - val_loss: 0.0171\n",
      "Epoch 749/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0200\n",
      "Epoch 750/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0060 - val_loss: 0.0178\n",
      "Epoch 751/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0201\n",
      "Epoch 752/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0186\n",
      "Epoch 753/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0056 - val_loss: 0.0198\n",
      "Epoch 754/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0063 - val_loss: 0.0187\n",
      "Epoch 755/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 756/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0067 - val_loss: 0.0177\n",
      "Epoch 757/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0057 - val_loss: 0.0189\n",
      "Epoch 758/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0063 - val_loss: 0.0182\n",
      "Epoch 759/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 760/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0071 - val_loss: 0.0167\n",
      "Epoch 761/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0164\n",
      "Epoch 762/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0064 - val_loss: 0.0180\n",
      "Epoch 763/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0176\n",
      "Epoch 764/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0065 - val_loss: 0.0176\n",
      "Epoch 765/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0055 - val_loss: 0.0189\n",
      "Epoch 766/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0178\n",
      "Epoch 767/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0191\n",
      "Epoch 768/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0060 - val_loss: 0.0184\n",
      "Epoch 769/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0066 - val_loss: 0.0186\n",
      "Epoch 770/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0058 - val_loss: 0.0166\n",
      "Epoch 771/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0066 - val_loss: 0.0172\n",
      "Epoch 772/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0070 - val_loss: 0.0185\n",
      "Epoch 773/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0058 - val_loss: 0.0184\n",
      "Epoch 774/2000\n",
      "1312/1312 [==============================] - 0s 110us/step - loss: 0.0063 - val_loss: 0.0177\n",
      "Epoch 775/2000\n",
      "1312/1312 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0167\n",
      "Epoch 776/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0056 - val_loss: 0.0196\n",
      "Epoch 777/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0065 - val_loss: 0.0171\n",
      "Epoch 778/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0057 - val_loss: 0.0180\n",
      "Epoch 779/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0064 - val_loss: 0.0179\n",
      "Epoch 780/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0185\n",
      "Epoch 781/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0072 - val_loss: 0.0177\n",
      "Epoch 782/2000\n",
      "1312/1312 [==============================] - 0s 128us/step - loss: 0.0067 - val_loss: 0.0187\n",
      "Epoch 783/2000\n",
      "1312/1312 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0223\n",
      "Epoch 784/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0189\n",
      "Epoch 785/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0057 - val_loss: 0.0175\n",
      "Epoch 786/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0066 - val_loss: 0.0181\n",
      "Epoch 787/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0066 - val_loss: 0.0192\n",
      "Epoch 788/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0063 - val_loss: 0.0180\n",
      "Epoch 789/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0055 - val_loss: 0.0185\n",
      "Epoch 790/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0057 - val_loss: 0.0200\n",
      "Epoch 791/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 792/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0063 - val_loss: 0.0190\n",
      "Epoch 793/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0062 - val_loss: 0.0194\n",
      "Epoch 794/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0178\n",
      "Epoch 795/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0180\n",
      "Epoch 796/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0193\n",
      "Epoch 797/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0065 - val_loss: 0.0190\n",
      "Epoch 798/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0058 - val_loss: 0.0179\n",
      "Epoch 799/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0071 - val_loss: 0.0183\n",
      "Epoch 800/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0058 - val_loss: 0.0173\n",
      "Epoch 801/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0064 - val_loss: 0.0182\n",
      "Epoch 802/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0052 - val_loss: 0.0202\n",
      "Epoch 803/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0055 - val_loss: 0.0209\n",
      "Epoch 804/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0058 - val_loss: 0.0187\n",
      "Epoch 805/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0067 - val_loss: 0.0179\n",
      "Epoch 806/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0058 - val_loss: 0.0181\n",
      "Epoch 807/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0066 - val_loss: 0.0173\n",
      "Epoch 808/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0059 - val_loss: 0.0178\n",
      "Epoch 809/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0193\n",
      "Epoch 810/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0058 - val_loss: 0.0172\n",
      "Epoch 811/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0173\n",
      "Epoch 812/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0059 - val_loss: 0.0195\n",
      "Epoch 813/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0070 - val_loss: 0.0177\n",
      "Epoch 814/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0073 - val_loss: 0.0201\n",
      "Epoch 815/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0074 - val_loss: 0.0178\n",
      "Epoch 816/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0056 - val_loss: 0.0200\n",
      "Epoch 817/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 818/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0071 - val_loss: 0.0194\n",
      "Epoch 819/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0061 - val_loss: 0.0174\n",
      "Epoch 820/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0075 - val_loss: 0.0184\n",
      "Epoch 821/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0054 - val_loss: 0.0183\n",
      "Epoch 822/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0170\n",
      "Epoch 823/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0055 - val_loss: 0.0192\n",
      "Epoch 824/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0192\n",
      "Epoch 825/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0057 - val_loss: 0.0172\n",
      "Epoch 826/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0061 - val_loss: 0.0188\n",
      "Epoch 827/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0059 - val_loss: 0.0187\n",
      "Epoch 828/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0071 - val_loss: 0.0187\n",
      "Epoch 829/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0059 - val_loss: 0.0229\n",
      "Epoch 830/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 831/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0064 - val_loss: 0.0162\n",
      "Epoch 832/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0072 - val_loss: 0.0183\n",
      "Epoch 833/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0174\n",
      "Epoch 834/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 835/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0056 - val_loss: 0.0188\n",
      "Epoch 836/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0056 - val_loss: 0.0177\n",
      "Epoch 837/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0054 - val_loss: 0.0189\n",
      "Epoch 838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0052 - val_loss: 0.0170\n",
      "Epoch 839/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0060 - val_loss: 0.0175\n",
      "Epoch 840/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0055 - val_loss: 0.0181\n",
      "Epoch 841/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0068 - val_loss: 0.0191\n",
      "Epoch 842/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0065 - val_loss: 0.0196\n",
      "Epoch 843/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0057 - val_loss: 0.0192\n",
      "Epoch 844/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0061 - val_loss: 0.0182\n",
      "Epoch 845/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0057 - val_loss: 0.0173\n",
      "Epoch 846/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0180\n",
      "Epoch 847/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0067 - val_loss: 0.0179\n",
      "Epoch 848/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0078 - val_loss: 0.0204\n",
      "Epoch 849/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0066 - val_loss: 0.0186\n",
      "Epoch 850/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0171\n",
      "Epoch 851/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0055 - val_loss: 0.0188\n",
      "Epoch 852/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0183\n",
      "Epoch 853/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0063 - val_loss: 0.0167\n",
      "Epoch 854/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0055 - val_loss: 0.0188\n",
      "Epoch 855/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0055 - val_loss: 0.0193\n",
      "Epoch 856/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0055 - val_loss: 0.0197\n",
      "Epoch 857/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0180\n",
      "Epoch 858/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 859/2000\n",
      "1312/1312 [==============================] - 0s 114us/step - loss: 0.0075 - val_loss: 0.0203\n",
      "Epoch 860/2000\n",
      "1312/1312 [==============================] - 0s 130us/step - loss: 0.0056 - val_loss: 0.0179\n",
      "Epoch 861/2000\n",
      "1312/1312 [==============================] - 0s 129us/step - loss: 0.0060 - val_loss: 0.0195\n",
      "Epoch 862/2000\n",
      "1312/1312 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0184\n",
      "Epoch 863/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0069 - val_loss: 0.0203\n",
      "Epoch 864/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.0054 - val_loss: 0.0179\n",
      "Epoch 865/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0057 - val_loss: 0.0175\n",
      "Epoch 866/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0050 - val_loss: 0.0170\n",
      "Epoch 867/2000\n",
      "1312/1312 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0186\n",
      "Epoch 868/2000\n",
      "1312/1312 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0183\n",
      "Epoch 869/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0055 - val_loss: 0.0198\n",
      "Epoch 870/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0058 - val_loss: 0.0190\n",
      "Epoch 871/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0075 - val_loss: 0.0198\n",
      "Epoch 872/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0180\n",
      "Epoch 873/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0168\n",
      "Epoch 874/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0188\n",
      "Epoch 875/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0190\n",
      "Epoch 876/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0174\n",
      "Epoch 877/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0174\n",
      "Epoch 878/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0058 - val_loss: 0.0187\n",
      "Epoch 879/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0188\n",
      "Epoch 880/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0054 - val_loss: 0.0212\n",
      "Epoch 881/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0059 - val_loss: 0.0185\n",
      "Epoch 882/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0192\n",
      "Epoch 883/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0067 - val_loss: 0.0226\n",
      "Epoch 884/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0192\n",
      "Epoch 885/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0198\n",
      "Epoch 886/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0060 - val_loss: 0.0187\n",
      "Epoch 887/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0048 - val_loss: 0.0201\n",
      "Epoch 888/2000\n",
      "1312/1312 [==============================] - 0s 116us/step - loss: 0.0059 - val_loss: 0.0191\n",
      "Epoch 889/2000\n",
      "1312/1312 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0199\n",
      "Epoch 890/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0061 - val_loss: 0.0199\n",
      "Epoch 891/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0059 - val_loss: 0.0178\n",
      "Epoch 892/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0059 - val_loss: 0.0208\n",
      "Epoch 893/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0062 - val_loss: 0.0189\n",
      "Epoch 894/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0050 - val_loss: 0.0206\n",
      "Epoch 895/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 896/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0058 - val_loss: 0.0198\n",
      "Epoch 897/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 898/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0048 - val_loss: 0.0197\n",
      "Epoch 899/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0059 - val_loss: 0.0185\n",
      "Epoch 900/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0065 - val_loss: 0.0194\n",
      "Epoch 901/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0053 - val_loss: 0.0178\n",
      "Epoch 902/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0056 - val_loss: 0.0193\n",
      "Epoch 903/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0058 - val_loss: 0.0192\n",
      "Epoch 904/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0069 - val_loss: 0.0182\n",
      "Epoch 905/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 906/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0203\n",
      "Epoch 907/2000\n",
      "1312/1312 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 908/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0053 - val_loss: 0.0186\n",
      "Epoch 909/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0188\n",
      "Epoch 910/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0061 - val_loss: 0.0175\n",
      "Epoch 911/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0055 - val_loss: 0.0180\n",
      "Epoch 912/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0182\n",
      "Epoch 913/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0056 - val_loss: 0.0173\n",
      "Epoch 914/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0054 - val_loss: 0.0171\n",
      "Epoch 915/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0056 - val_loss: 0.0193\n",
      "Epoch 916/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0068 - val_loss: 0.0176\n",
      "Epoch 917/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0049 - val_loss: 0.0179\n",
      "Epoch 918/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0068 - val_loss: 0.0161\n",
      "Epoch 919/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0056 - val_loss: 0.0174\n",
      "Epoch 920/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0062 - val_loss: 0.0183\n",
      "Epoch 921/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0049 - val_loss: 0.0170\n",
      "Epoch 922/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0173\n",
      "Epoch 923/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0202\n",
      "Epoch 924/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0053 - val_loss: 0.0177\n",
      "Epoch 925/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0052 - val_loss: 0.0164\n",
      "Epoch 926/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0055 - val_loss: 0.0188\n",
      "Epoch 927/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0183\n",
      "Epoch 928/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0061 - val_loss: 0.0167\n",
      "Epoch 929/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0060 - val_loss: 0.0203\n",
      "Epoch 930/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0052 - val_loss: 0.0191\n",
      "Epoch 931/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0186\n",
      "Epoch 932/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0055 - val_loss: 0.0225\n",
      "Epoch 933/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0058 - val_loss: 0.0174\n",
      "Epoch 934/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0186\n",
      "Epoch 935/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0058 - val_loss: 0.0220\n",
      "Epoch 936/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0063 - val_loss: 0.0205\n",
      "Epoch 937/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0056 - val_loss: 0.0198\n",
      "Epoch 938/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 939/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0054 - val_loss: 0.0204\n",
      "Epoch 940/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0055 - val_loss: 0.0181\n",
      "Epoch 941/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 942/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0048 - val_loss: 0.0202\n",
      "Epoch 943/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0061 - val_loss: 0.0161\n",
      "Epoch 944/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0065 - val_loss: 0.0165\n",
      "Epoch 945/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0201\n",
      "Epoch 946/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0056 - val_loss: 0.0183\n",
      "Epoch 947/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0049 - val_loss: 0.0190\n",
      "Epoch 948/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0046 - val_loss: 0.0178\n",
      "Epoch 949/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0064 - val_loss: 0.0185\n",
      "Epoch 950/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0063 - val_loss: 0.0205\n",
      "Epoch 951/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0065 - val_loss: 0.0194\n",
      "Epoch 952/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0187\n",
      "Epoch 953/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0058 - val_loss: 0.0184\n",
      "Epoch 954/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0053 - val_loss: 0.0179\n",
      "Epoch 955/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0063 - val_loss: 0.0176\n",
      "Epoch 956/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0187\n",
      "Epoch 957/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 958/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0201\n",
      "Epoch 959/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 960/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0050 - val_loss: 0.0182\n",
      "Epoch 961/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0054 - val_loss: 0.0183\n",
      "Epoch 962/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0173\n",
      "Epoch 963/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0054 - val_loss: 0.0195\n",
      "Epoch 964/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 965/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0200\n",
      "Epoch 966/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.0071 - val_loss: 0.0188\n",
      "Epoch 967/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 968/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0050 - val_loss: 0.0160\n",
      "Epoch 969/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0165\n",
      "Epoch 970/2000\n",
      "1312/1312 [==============================] - 0s 108us/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 971/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0062 - val_loss: 0.0181\n",
      "Epoch 972/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0048 - val_loss: 0.0183\n",
      "Epoch 973/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0046 - val_loss: 0.0185\n",
      "Epoch 974/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0057 - val_loss: 0.0184\n",
      "Epoch 975/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0044 - val_loss: 0.0169\n",
      "Epoch 976/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0174\n",
      "Epoch 977/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 978/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0175\n",
      "Epoch 979/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0192\n",
      "Epoch 980/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0043 - val_loss: 0.0187\n",
      "Epoch 981/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0047 - val_loss: 0.0190\n",
      "Epoch 982/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0199\n",
      "Epoch 983/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 984/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 985/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0048 - val_loss: 0.0194\n",
      "Epoch 986/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0048 - val_loss: 0.0181\n",
      "Epoch 987/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0041 - val_loss: 0.0179\n",
      "Epoch 988/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 989/2000\n",
      "1312/1312 [==============================] - 0s 113us/step - loss: 0.0063 - val_loss: 0.0172\n",
      "Epoch 990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0061 - val_loss: 0.0178\n",
      "Epoch 991/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0053 - val_loss: 0.0177\n",
      "Epoch 992/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0060 - val_loss: 0.0185\n",
      "Epoch 993/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0055 - val_loss: 0.0178\n",
      "Epoch 994/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0054 - val_loss: 0.0183\n",
      "Epoch 995/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0049 - val_loss: 0.0180\n",
      "Epoch 996/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0207\n",
      "Epoch 997/2000\n",
      "1312/1312 [==============================] - 0s 86us/step - loss: 0.0064 - val_loss: 0.0174\n",
      "Epoch 998/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0042 - val_loss: 0.0201\n",
      "Epoch 999/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0047 - val_loss: 0.0188\n",
      "Epoch 1000/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0047 - val_loss: 0.0182\n",
      "Epoch 1001/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0199\n",
      "Epoch 1002/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0173\n",
      "Epoch 1003/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0054 - val_loss: 0.0173\n",
      "Epoch 1004/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0201\n",
      "Epoch 1005/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0056 - val_loss: 0.0198\n",
      "Epoch 1006/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0182\n",
      "Epoch 1007/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0054 - val_loss: 0.0179\n",
      "Epoch 1008/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0054 - val_loss: 0.0177\n",
      "Epoch 1009/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0049 - val_loss: 0.0187\n",
      "Epoch 1010/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0174\n",
      "Epoch 1011/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 1012/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0192\n",
      "Epoch 1013/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0066 - val_loss: 0.0177\n",
      "Epoch 1014/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0181\n",
      "Epoch 1015/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0183\n",
      "Epoch 1016/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0043 - val_loss: 0.0179\n",
      "Epoch 1017/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0052 - val_loss: 0.0173\n",
      "Epoch 1018/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0054 - val_loss: 0.0199\n",
      "Epoch 1019/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0194\n",
      "Epoch 1020/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0194\n",
      "Epoch 1021/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0203\n",
      "Epoch 1022/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1023/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0054 - val_loss: 0.0179\n",
      "Epoch 1024/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 1025/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0173\n",
      "Epoch 1026/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0173\n",
      "Epoch 1027/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0171\n",
      "Epoch 1028/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0184\n",
      "Epoch 1029/2000\n",
      "1312/1312 [==============================] - 0s 99us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1030/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1031/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0049 - val_loss: 0.0181\n",
      "Epoch 1032/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0050 - val_loss: 0.0183\n",
      "Epoch 1033/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0182\n",
      "Epoch 1034/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0187\n",
      "Epoch 1035/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0176\n",
      "Epoch 1036/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0066 - val_loss: 0.0173\n",
      "Epoch 1037/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0192\n",
      "Epoch 1038/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0195\n",
      "Epoch 1039/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0058 - val_loss: 0.0190\n",
      "Epoch 1040/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0178\n",
      "Epoch 1041/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0051 - val_loss: 0.0169\n",
      "Epoch 1042/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0052 - val_loss: 0.0205\n",
      "Epoch 1043/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0047 - val_loss: 0.0192\n",
      "Epoch 1044/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 1045/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0177\n",
      "Epoch 1046/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0177\n",
      "Epoch 1047/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0180\n",
      "Epoch 1048/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0163\n",
      "Epoch 1049/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0182\n",
      "Epoch 1050/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0166\n",
      "Epoch 1051/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0047 - val_loss: 0.0195\n",
      "Epoch 1052/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0047 - val_loss: 0.0189\n",
      "Epoch 1053/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 1054/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0045 - val_loss: 0.0188\n",
      "Epoch 1055/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0191\n",
      "Epoch 1056/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0190\n",
      "Epoch 1057/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1058/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0052 - val_loss: 0.0204\n",
      "Epoch 1059/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0176\n",
      "Epoch 1060/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0175\n",
      "Epoch 1061/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0183\n",
      "Epoch 1062/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0188\n",
      "Epoch 1063/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0188\n",
      "Epoch 1064/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0190\n",
      "Epoch 1065/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0184\n",
      "Epoch 1066/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0057 - val_loss: 0.0174\n",
      "Epoch 1067/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0162\n",
      "Epoch 1068/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0056 - val_loss: 0.0189\n",
      "Epoch 1069/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0164\n",
      "Epoch 1070/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0058 - val_loss: 0.0187\n",
      "Epoch 1071/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0177\n",
      "Epoch 1072/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0168\n",
      "Epoch 1073/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0058 - val_loss: 0.0182\n",
      "Epoch 1074/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0166\n",
      "Epoch 1075/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0176\n",
      "Epoch 1076/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0050 - val_loss: 0.0174\n",
      "Epoch 1077/2000\n",
      "1312/1312 [==============================] - 0s 96us/step - loss: 0.0049 - val_loss: 0.0180\n",
      "Epoch 1078/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0060 - val_loss: 0.0196\n",
      "Epoch 1079/2000\n",
      "1312/1312 [==============================] - 0s 84us/step - loss: 0.0052 - val_loss: 0.0182\n",
      "Epoch 1080/2000\n",
      "1312/1312 [==============================] - 0s 86us/step - loss: 0.0047 - val_loss: 0.0160\n",
      "Epoch 1081/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0047 - val_loss: 0.0165\n",
      "Epoch 1082/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1083/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0048 - val_loss: 0.0171\n",
      "Epoch 1084/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0045 - val_loss: 0.0165\n",
      "Epoch 1085/2000\n",
      "1312/1312 [==============================] - 0s 84us/step - loss: 0.0052 - val_loss: 0.0196\n",
      "Epoch 1086/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0172\n",
      "Epoch 1087/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0035 - val_loss: 0.0161\n",
      "Epoch 1088/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0175\n",
      "Epoch 1089/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0047 - val_loss: 0.0177\n",
      "Epoch 1090/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0049 - val_loss: 0.0164\n",
      "Epoch 1091/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0186\n",
      "Epoch 1092/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0182\n",
      "Epoch 1093/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1094/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0054 - val_loss: 0.0160\n",
      "Epoch 1095/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0046 - val_loss: 0.0166\n",
      "Epoch 1096/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0048 - val_loss: 0.0170\n",
      "Epoch 1097/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0045 - val_loss: 0.0174\n",
      "Epoch 1098/2000\n",
      "1312/1312 [==============================] - 0s 84us/step - loss: 0.0046 - val_loss: 0.0199\n",
      "Epoch 1099/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0172\n",
      "Epoch 1100/2000\n",
      "1312/1312 [==============================] - 0s 84us/step - loss: 0.0051 - val_loss: 0.0192\n",
      "Epoch 1101/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 1102/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0045 - val_loss: 0.0162\n",
      "Epoch 1103/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0048 - val_loss: 0.0170\n",
      "Epoch 1104/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0054 - val_loss: 0.0187\n",
      "Epoch 1105/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0043 - val_loss: 0.0176\n",
      "Epoch 1106/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0047 - val_loss: 0.0199\n",
      "Epoch 1107/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0046 - val_loss: 0.0198\n",
      "Epoch 1108/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0056 - val_loss: 0.0197\n",
      "Epoch 1109/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0199\n",
      "Epoch 1110/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0180\n",
      "Epoch 1111/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0055 - val_loss: 0.0196\n",
      "Epoch 1112/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 1113/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0176\n",
      "Epoch 1114/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0176\n",
      "Epoch 1115/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0051 - val_loss: 0.0162\n",
      "Epoch 1116/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0060 - val_loss: 0.0193\n",
      "Epoch 1117/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 1118/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 1119/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0059 - val_loss: 0.0190\n",
      "Epoch 1120/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 1121/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0186\n",
      "Epoch 1122/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0178\n",
      "Epoch 1123/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0047 - val_loss: 0.0182\n",
      "Epoch 1124/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0186\n",
      "Epoch 1125/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 1126/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0050 - val_loss: 0.0179\n",
      "Epoch 1127/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0208\n",
      "Epoch 1128/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0172\n",
      "Epoch 1129/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0047 - val_loss: 0.0172\n",
      "Epoch 1130/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0176\n",
      "Epoch 1131/2000\n",
      "1312/1312 [==============================] - 0s 86us/step - loss: 0.0048 - val_loss: 0.0188\n",
      "Epoch 1132/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 1133/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0046 - val_loss: 0.0155\n",
      "Epoch 1134/2000\n",
      "1312/1312 [==============================] - 0s 85us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 1135/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0062 - val_loss: 0.0171\n",
      "Epoch 1136/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1137/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0170\n",
      "Epoch 1138/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0178\n",
      "Epoch 1139/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 1140/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0199\n",
      "Epoch 1141/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0051 - val_loss: 0.0169\n",
      "Epoch 1142/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0189\n",
      "Epoch 1143/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0189\n",
      "Epoch 1144/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0052 - val_loss: 0.0179\n",
      "Epoch 1145/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0210\n",
      "Epoch 1146/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0181\n",
      "Epoch 1147/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0038 - val_loss: 0.0179\n",
      "Epoch 1148/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0180\n",
      "Epoch 1149/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0182\n",
      "Epoch 1150/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0184\n",
      "Epoch 1151/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 1152/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0174\n",
      "Epoch 1153/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0177\n",
      "Epoch 1154/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0167\n",
      "Epoch 1155/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0167\n",
      "Epoch 1156/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0174\n",
      "Epoch 1157/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0051 - val_loss: 0.0186\n",
      "Epoch 1158/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0190\n",
      "Epoch 1159/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0059 - val_loss: 0.0204\n",
      "Epoch 1160/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 1161/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0175\n",
      "Epoch 1162/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0049 - val_loss: 0.0179\n",
      "Epoch 1163/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1164/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0167\n",
      "Epoch 1165/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0179\n",
      "Epoch 1166/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0192\n",
      "Epoch 1167/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0188\n",
      "Epoch 1168/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0188\n",
      "Epoch 1169/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0201\n",
      "Epoch 1170/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0179\n",
      "Epoch 1171/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0187\n",
      "Epoch 1172/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0190\n",
      "Epoch 1173/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0165\n",
      "Epoch 1174/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 1175/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0044 - val_loss: 0.0194\n",
      "Epoch 1176/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0189\n",
      "Epoch 1177/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0208\n",
      "Epoch 1178/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 1179/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0175\n",
      "Epoch 1180/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0175\n",
      "Epoch 1181/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0175\n",
      "Epoch 1182/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0186\n",
      "Epoch 1183/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0177\n",
      "Epoch 1184/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0061 - val_loss: 0.0197\n",
      "Epoch 1185/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0186\n",
      "Epoch 1186/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0173\n",
      "Epoch 1187/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0164\n",
      "Epoch 1188/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 1189/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0040 - val_loss: 0.0183\n",
      "Epoch 1190/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0050 - val_loss: 0.0171\n",
      "Epoch 1191/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0183\n",
      "Epoch 1192/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0173\n",
      "Epoch 1193/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1194/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0044 - val_loss: 0.0199\n",
      "Epoch 1195/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0181\n",
      "Epoch 1196/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0172\n",
      "Epoch 1197/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0182\n",
      "Epoch 1198/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0173\n",
      "Epoch 1199/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0045 - val_loss: 0.0187\n",
      "Epoch 1200/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0180\n",
      "Epoch 1201/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0188\n",
      "Epoch 1202/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0194\n",
      "Epoch 1203/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1204/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0037 - val_loss: 0.0191\n",
      "Epoch 1205/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0187\n",
      "Epoch 1206/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0193\n",
      "Epoch 1207/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1208/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0180\n",
      "Epoch 1209/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0180\n",
      "Epoch 1210/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0204\n",
      "Epoch 1211/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0183\n",
      "Epoch 1212/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1213/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0037 - val_loss: 0.0176\n",
      "Epoch 1214/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0178\n",
      "Epoch 1215/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0042 - val_loss: 0.0165\n",
      "Epoch 1216/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0180\n",
      "Epoch 1217/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0169\n",
      "Epoch 1218/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0180\n",
      "Epoch 1219/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0219\n",
      "Epoch 1220/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0178\n",
      "Epoch 1221/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0196\n",
      "Epoch 1222/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1223/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1224/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0178\n",
      "Epoch 1225/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0040 - val_loss: 0.0170\n",
      "Epoch 1226/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0172\n",
      "Epoch 1227/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0171\n",
      "Epoch 1228/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0189\n",
      "Epoch 1229/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 1230/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0177\n",
      "Epoch 1231/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0190\n",
      "Epoch 1232/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0183\n",
      "Epoch 1233/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0054 - val_loss: 0.0191\n",
      "Epoch 1234/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0183\n",
      "Epoch 1235/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0186\n",
      "Epoch 1236/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0177\n",
      "Epoch 1237/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0170\n",
      "Epoch 1238/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 1239/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0038 - val_loss: 0.0190\n",
      "Epoch 1240/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0039 - val_loss: 0.0171\n",
      "Epoch 1241/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0061 - val_loss: 0.0178\n",
      "Epoch 1242/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0178\n",
      "Epoch 1243/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0185\n",
      "Epoch 1244/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0049 - val_loss: 0.0190\n",
      "Epoch 1245/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0060 - val_loss: 0.0181\n",
      "Epoch 1246/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0178\n",
      "Epoch 1247/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0185\n",
      "Epoch 1248/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0175\n",
      "Epoch 1249/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0193\n",
      "Epoch 1250/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0176\n",
      "Epoch 1251/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0199\n",
      "Epoch 1252/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0176\n",
      "Epoch 1253/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0180\n",
      "Epoch 1254/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0177\n",
      "Epoch 1255/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0043 - val_loss: 0.0197\n",
      "Epoch 1256/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0184\n",
      "Epoch 1257/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0166\n",
      "Epoch 1258/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0181\n",
      "Epoch 1259/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 1260/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0178\n",
      "Epoch 1261/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0173\n",
      "Epoch 1262/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1263/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0035 - val_loss: 0.0204\n",
      "Epoch 1264/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0047 - val_loss: 0.0184\n",
      "Epoch 1265/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0040 - val_loss: 0.0173\n",
      "Epoch 1266/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0179\n",
      "Epoch 1267/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0169\n",
      "Epoch 1268/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0172\n",
      "Epoch 1269/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0195\n",
      "Epoch 1270/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0176\n",
      "Epoch 1271/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0068 - val_loss: 0.0208\n",
      "Epoch 1272/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0184\n",
      "Epoch 1273/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0184\n",
      "Epoch 1274/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0184\n",
      "Epoch 1275/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 1276/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0182\n",
      "Epoch 1277/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0201\n",
      "Epoch 1278/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0192\n",
      "Epoch 1279/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0173\n",
      "Epoch 1280/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0183\n",
      "Epoch 1281/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0173\n",
      "Epoch 1282/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0184\n",
      "Epoch 1283/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0173\n",
      "Epoch 1284/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0198\n",
      "Epoch 1285/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0073 - val_loss: 0.0182\n",
      "Epoch 1286/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0210\n",
      "Epoch 1287/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0060 - val_loss: 0.0187\n",
      "Epoch 1288/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0170\n",
      "Epoch 1289/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0183\n",
      "Epoch 1290/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0177\n",
      "Epoch 1291/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0180\n",
      "Epoch 1292/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0040 - val_loss: 0.0176\n",
      "Epoch 1293/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0053 - val_loss: 0.0190\n",
      "Epoch 1295/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0166\n",
      "Epoch 1296/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1297/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0177\n",
      "Epoch 1298/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0188\n",
      "Epoch 1299/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0182\n",
      "Epoch 1300/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 1301/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0050 - val_loss: 0.0173\n",
      "Epoch 1302/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0209\n",
      "Epoch 1303/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0206\n",
      "Epoch 1304/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0177\n",
      "Epoch 1305/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 1306/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0198\n",
      "Epoch 1307/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1308/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1309/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 1310/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0183\n",
      "Epoch 1311/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0194\n",
      "Epoch 1312/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0181\n",
      "Epoch 1313/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0177\n",
      "Epoch 1314/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0199\n",
      "Epoch 1315/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0052 - val_loss: 0.0203\n",
      "Epoch 1316/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 1317/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0045 - val_loss: 0.0185\n",
      "Epoch 1318/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0041 - val_loss: 0.0199\n",
      "Epoch 1319/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0193\n",
      "Epoch 1320/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0196\n",
      "Epoch 1321/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0170\n",
      "Epoch 1322/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0176\n",
      "Epoch 1323/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0184\n",
      "Epoch 1324/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0166\n",
      "Epoch 1325/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0038 - val_loss: 0.0194\n",
      "Epoch 1326/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0181\n",
      "Epoch 1327/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0175\n",
      "Epoch 1328/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0169\n",
      "Epoch 1329/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0177\n",
      "Epoch 1330/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0179\n",
      "Epoch 1331/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0064 - val_loss: 0.0183\n",
      "Epoch 1332/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0180\n",
      "Epoch 1333/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1334/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0190\n",
      "Epoch 1335/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 1336/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0181\n",
      "Epoch 1337/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0049 - val_loss: 0.0198\n",
      "Epoch 1338/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0190\n",
      "Epoch 1339/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 1340/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0052 - val_loss: 0.0176\n",
      "Epoch 1341/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0183\n",
      "Epoch 1342/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0052 - val_loss: 0.0174\n",
      "Epoch 1343/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0045 - val_loss: 0.0172\n",
      "Epoch 1344/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0040 - val_loss: 0.0180\n",
      "Epoch 1345/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 1346/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0180\n",
      "Epoch 1347/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0036 - val_loss: 0.0170\n",
      "Epoch 1348/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0200\n",
      "Epoch 1349/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0185\n",
      "Epoch 1350/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0183\n",
      "Epoch 1351/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0199\n",
      "Epoch 1352/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0180\n",
      "Epoch 1353/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0172\n",
      "Epoch 1354/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0180\n",
      "Epoch 1355/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0202\n",
      "Epoch 1356/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0185\n",
      "Epoch 1357/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0168\n",
      "Epoch 1358/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0177\n",
      "Epoch 1359/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 1360/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0185\n",
      "Epoch 1361/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 1362/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0193\n",
      "Epoch 1363/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0044 - val_loss: 0.0171\n",
      "Epoch 1364/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0206\n",
      "Epoch 1365/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0206\n",
      "Epoch 1366/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 1367/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0177\n",
      "Epoch 1368/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0174\n",
      "Epoch 1369/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 1370/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 1371/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0188\n",
      "Epoch 1372/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0180\n",
      "Epoch 1373/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0204\n",
      "Epoch 1374/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 1375/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0171\n",
      "Epoch 1376/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0039 - val_loss: 0.0182\n",
      "Epoch 1377/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 1378/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0198\n",
      "Epoch 1379/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1380/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1381/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0038 - val_loss: 0.0174\n",
      "Epoch 1382/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0040 - val_loss: 0.0191\n",
      "Epoch 1383/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0169\n",
      "Epoch 1384/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0180\n",
      "Epoch 1385/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0213\n",
      "Epoch 1386/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0041 - val_loss: 0.0167\n",
      "Epoch 1387/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0184\n",
      "Epoch 1388/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0172\n",
      "Epoch 1389/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0198\n",
      "Epoch 1390/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0188\n",
      "Epoch 1391/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0163\n",
      "Epoch 1392/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0168\n",
      "Epoch 1393/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1394/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0166\n",
      "Epoch 1395/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0196\n",
      "Epoch 1396/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0175\n",
      "Epoch 1397/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0175\n",
      "Epoch 1398/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0180\n",
      "Epoch 1399/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 1400/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0181\n",
      "Epoch 1401/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0191\n",
      "Epoch 1402/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0173\n",
      "Epoch 1403/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 1404/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0170\n",
      "Epoch 1405/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0178\n",
      "Epoch 1406/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0047 - val_loss: 0.0185\n",
      "Epoch 1407/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0054 - val_loss: 0.0182\n",
      "Epoch 1408/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0184\n",
      "Epoch 1409/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 1410/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0181\n",
      "Epoch 1411/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0186\n",
      "Epoch 1412/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0188\n",
      "Epoch 1413/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0038 - val_loss: 0.0176\n",
      "Epoch 1414/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0185\n",
      "Epoch 1415/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0191\n",
      "Epoch 1416/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0210\n",
      "Epoch 1417/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 1418/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0189\n",
      "Epoch 1419/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0038 - val_loss: 0.0175\n",
      "Epoch 1420/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0193\n",
      "Epoch 1421/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0192\n",
      "Epoch 1422/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0182\n",
      "Epoch 1423/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0188\n",
      "Epoch 1424/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0172\n",
      "Epoch 1425/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0174\n",
      "Epoch 1426/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0194\n",
      "Epoch 1427/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1428/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0182\n",
      "Epoch 1429/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 1430/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0205\n",
      "Epoch 1431/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1432/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 1433/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0169\n",
      "Epoch 1434/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0182\n",
      "Epoch 1435/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0040 - val_loss: 0.0195\n",
      "Epoch 1436/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 1437/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0205\n",
      "Epoch 1438/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0186\n",
      "Epoch 1439/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0175\n",
      "Epoch 1440/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0188\n",
      "Epoch 1441/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0194\n",
      "Epoch 1442/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1443/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0189\n",
      "Epoch 1444/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 1445/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0185\n",
      "Epoch 1446/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0183\n",
      "Epoch 1447/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0177\n",
      "Epoch 1448/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0058 - val_loss: 0.0167\n",
      "Epoch 1449/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0192\n",
      "Epoch 1450/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0168\n",
      "Epoch 1451/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0186\n",
      "Epoch 1452/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0185\n",
      "Epoch 1453/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0182\n",
      "Epoch 1454/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0197\n",
      "Epoch 1455/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0178\n",
      "Epoch 1456/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0169\n",
      "Epoch 1457/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0178\n",
      "Epoch 1458/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0167\n",
      "Epoch 1459/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0177\n",
      "Epoch 1460/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0172\n",
      "Epoch 1461/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0038 - val_loss: 0.0188\n",
      "Epoch 1462/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0172\n",
      "Epoch 1463/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0046 - val_loss: 0.0169\n",
      "Epoch 1464/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 1465/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0171\n",
      "Epoch 1466/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0172\n",
      "Epoch 1467/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0175\n",
      "Epoch 1468/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0177\n",
      "Epoch 1469/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0176\n",
      "Epoch 1470/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0177\n",
      "Epoch 1471/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0183\n",
      "Epoch 1472/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0187\n",
      "Epoch 1473/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0177\n",
      "Epoch 1474/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0183\n",
      "Epoch 1475/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0201\n",
      "Epoch 1476/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 1477/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0181\n",
      "Epoch 1478/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0184\n",
      "Epoch 1479/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0176\n",
      "Epoch 1480/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0195\n",
      "Epoch 1481/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0181\n",
      "Epoch 1482/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0170\n",
      "Epoch 1483/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0172\n",
      "Epoch 1484/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0164\n",
      "Epoch 1485/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0181\n",
      "Epoch 1486/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0174\n",
      "Epoch 1487/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1488/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0172\n",
      "Epoch 1489/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0168\n",
      "Epoch 1490/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0199\n",
      "Epoch 1491/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0171\n",
      "Epoch 1492/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0186\n",
      "Epoch 1493/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0189\n",
      "Epoch 1494/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0054 - val_loss: 0.0176\n",
      "Epoch 1495/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 1496/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0195\n",
      "Epoch 1497/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0201\n",
      "Epoch 1498/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0190\n",
      "Epoch 1499/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0220\n",
      "Epoch 1500/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0060 - val_loss: 0.0205\n",
      "Epoch 1501/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0197\n",
      "Epoch 1502/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0191\n",
      "Epoch 1503/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0216\n",
      "Epoch 1504/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0202\n",
      "Epoch 1505/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0193\n",
      "Epoch 1506/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0193\n",
      "Epoch 1507/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0189\n",
      "Epoch 1508/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0190\n",
      "Epoch 1509/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0052 - val_loss: 0.0196\n",
      "Epoch 1510/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0194\n",
      "Epoch 1511/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0184\n",
      "Epoch 1512/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0170\n",
      "Epoch 1513/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0059 - val_loss: 0.0195\n",
      "Epoch 1514/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0195\n",
      "Epoch 1515/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 1516/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0166\n",
      "Epoch 1517/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0172\n",
      "Epoch 1518/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1519/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0042 - val_loss: 0.0166\n",
      "Epoch 1520/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0043 - val_loss: 0.0180\n",
      "Epoch 1521/2000\n",
      "1312/1312 [==============================] - 0s 106us/step - loss: 0.0054 - val_loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1522/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0178\n",
      "Epoch 1523/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0048 - val_loss: 0.0166\n",
      "Epoch 1524/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0042 - val_loss: 0.0170\n",
      "Epoch 1525/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0204\n",
      "Epoch 1526/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 1527/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0198\n",
      "Epoch 1528/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0163\n",
      "Epoch 1529/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0037 - val_loss: 0.0165\n",
      "Epoch 1530/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0195\n",
      "Epoch 1531/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0194\n",
      "Epoch 1532/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0077 - val_loss: 0.0172\n",
      "Epoch 1533/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0061 - val_loss: 0.0168\n",
      "Epoch 1534/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0044 - val_loss: 0.0205\n",
      "Epoch 1535/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0187\n",
      "Epoch 1536/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0051 - val_loss: 0.0186\n",
      "Epoch 1537/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0174\n",
      "Epoch 1538/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1539/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0177\n",
      "Epoch 1540/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0211\n",
      "Epoch 1541/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0180\n",
      "Epoch 1542/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 1543/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0057 - val_loss: 0.0181\n",
      "Epoch 1544/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0179\n",
      "Epoch 1545/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0176\n",
      "Epoch 1546/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0199\n",
      "Epoch 1547/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0187\n",
      "Epoch 1548/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0199\n",
      "Epoch 1549/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0191\n",
      "Epoch 1550/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0178\n",
      "Epoch 1551/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0198\n",
      "Epoch 1552/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1553/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 1554/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0038 - val_loss: 0.0195\n",
      "Epoch 1555/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0201\n",
      "Epoch 1556/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0199\n",
      "Epoch 1557/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0192\n",
      "Epoch 1558/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0185\n",
      "Epoch 1559/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0179\n",
      "Epoch 1560/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0181\n",
      "Epoch 1561/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1562/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0195\n",
      "Epoch 1563/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0187\n",
      "Epoch 1564/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0039 - val_loss: 0.0190\n",
      "Epoch 1565/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0175\n",
      "Epoch 1566/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1567/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0182\n",
      "Epoch 1568/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0180\n",
      "Epoch 1569/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0199\n",
      "Epoch 1570/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 1571/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0195\n",
      "Epoch 1572/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0209\n",
      "Epoch 1573/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 1574/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0187\n",
      "Epoch 1575/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0194\n",
      "Epoch 1576/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0068 - val_loss: 0.0196\n",
      "Epoch 1577/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0056 - val_loss: 0.0195\n",
      "Epoch 1578/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0207\n",
      "Epoch 1579/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0192\n",
      "Epoch 1580/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0186\n",
      "Epoch 1581/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0184\n",
      "Epoch 1582/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 1583/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0211\n",
      "Epoch 1584/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0204\n",
      "Epoch 1585/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0192\n",
      "Epoch 1586/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0038 - val_loss: 0.0196\n",
      "Epoch 1587/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0191\n",
      "Epoch 1588/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0199\n",
      "Epoch 1589/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0172\n",
      "Epoch 1590/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0059 - val_loss: 0.0210\n",
      "Epoch 1591/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0196\n",
      "Epoch 1592/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0188\n",
      "Epoch 1593/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0060 - val_loss: 0.0188\n",
      "Epoch 1594/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0182\n",
      "Epoch 1595/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0188\n",
      "Epoch 1596/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0213\n",
      "Epoch 1597/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0198\n",
      "Epoch 1599/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0184\n",
      "Epoch 1600/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0193\n",
      "Epoch 1601/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0039 - val_loss: 0.0195\n",
      "Epoch 1602/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0195\n",
      "Epoch 1603/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0190\n",
      "Epoch 1604/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0200\n",
      "Epoch 1605/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 1606/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0186\n",
      "Epoch 1607/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0217\n",
      "Epoch 1608/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0198\n",
      "Epoch 1609/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0186\n",
      "Epoch 1610/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1611/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0189\n",
      "Epoch 1612/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0051 - val_loss: 0.0216\n",
      "Epoch 1613/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0199\n",
      "Epoch 1614/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0041 - val_loss: 0.0194\n",
      "Epoch 1615/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0186\n",
      "Epoch 1616/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0190\n",
      "Epoch 1617/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0179\n",
      "Epoch 1618/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0039 - val_loss: 0.0191\n",
      "Epoch 1619/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0232\n",
      "Epoch 1620/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0063 - val_loss: 0.0178\n",
      "Epoch 1621/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0184\n",
      "Epoch 1622/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 1623/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 1624/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0208\n",
      "Epoch 1625/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0187\n",
      "Epoch 1626/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0179\n",
      "Epoch 1627/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0187\n",
      "Epoch 1628/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0180\n",
      "Epoch 1629/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0242\n",
      "Epoch 1630/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0209\n",
      "Epoch 1631/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0187\n",
      "Epoch 1632/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0183\n",
      "Epoch 1633/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0180\n",
      "Epoch 1634/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0192\n",
      "Epoch 1635/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0190\n",
      "Epoch 1636/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0197\n",
      "Epoch 1637/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0177\n",
      "Epoch 1638/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0181\n",
      "Epoch 1639/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0056 - val_loss: 0.0184\n",
      "Epoch 1640/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0192\n",
      "Epoch 1641/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0190\n",
      "Epoch 1642/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0198\n",
      "Epoch 1643/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0042 - val_loss: 0.0184\n",
      "Epoch 1644/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0171\n",
      "Epoch 1645/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0179\n",
      "Epoch 1646/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0166\n",
      "Epoch 1647/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0186\n",
      "Epoch 1648/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0206\n",
      "Epoch 1649/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0187\n",
      "Epoch 1650/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0186\n",
      "Epoch 1651/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0201\n",
      "Epoch 1652/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 1653/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 1654/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0174\n",
      "Epoch 1655/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0193\n",
      "Epoch 1656/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0189\n",
      "Epoch 1657/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0192\n",
      "Epoch 1658/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0177\n",
      "Epoch 1659/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0199\n",
      "Epoch 1660/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1661/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0041 - val_loss: 0.0205\n",
      "Epoch 1662/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0197\n",
      "Epoch 1663/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0051 - val_loss: 0.0208\n",
      "Epoch 1664/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0195\n",
      "Epoch 1665/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0177\n",
      "Epoch 1666/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0195\n",
      "Epoch 1667/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0182\n",
      "Epoch 1668/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0202\n",
      "Epoch 1669/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0194\n",
      "Epoch 1670/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0190\n",
      "Epoch 1671/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0049 - val_loss: 0.0176\n",
      "Epoch 1672/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0187\n",
      "Epoch 1673/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1674/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0184\n",
      "Epoch 1675/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0198\n",
      "Epoch 1676/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0188\n",
      "Epoch 1677/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0184\n",
      "Epoch 1678/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0056 - val_loss: 0.0174\n",
      "Epoch 1679/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0054 - val_loss: 0.0178\n",
      "Epoch 1680/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0054 - val_loss: 0.0178\n",
      "Epoch 1681/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0173\n",
      "Epoch 1682/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0173\n",
      "Epoch 1683/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0212\n",
      "Epoch 1684/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0186\n",
      "Epoch 1685/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0177\n",
      "Epoch 1686/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0043 - val_loss: 0.0175\n",
      "Epoch 1687/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0065 - val_loss: 0.0200\n",
      "Epoch 1688/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0057 - val_loss: 0.0190\n",
      "Epoch 1689/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0174\n",
      "Epoch 1690/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0180\n",
      "Epoch 1691/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0220\n",
      "Epoch 1692/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0188\n",
      "Epoch 1693/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 1694/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1695/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0185\n",
      "Epoch 1696/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0214\n",
      "Epoch 1697/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0205\n",
      "Epoch 1698/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0187\n",
      "Epoch 1699/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0190\n",
      "Epoch 1700/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 1701/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0191\n",
      "Epoch 1702/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0184\n",
      "Epoch 1703/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0040 - val_loss: 0.0178\n",
      "Epoch 1704/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0173\n",
      "Epoch 1705/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0183\n",
      "Epoch 1706/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0179\n",
      "Epoch 1707/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0180\n",
      "Epoch 1708/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0199\n",
      "Epoch 1709/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0217\n",
      "Epoch 1710/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1711/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0045 - val_loss: 0.0199\n",
      "Epoch 1712/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0190\n",
      "Epoch 1713/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0194\n",
      "Epoch 1714/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0037 - val_loss: 0.0188\n",
      "Epoch 1715/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0190\n",
      "Epoch 1716/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0203\n",
      "Epoch 1717/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0192\n",
      "Epoch 1718/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0209\n",
      "Epoch 1719/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0215\n",
      "Epoch 1720/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0180\n",
      "Epoch 1721/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0183\n",
      "Epoch 1722/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0183\n",
      "Epoch 1723/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0185\n",
      "Epoch 1724/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0178\n",
      "Epoch 1725/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0202\n",
      "Epoch 1726/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0198\n",
      "Epoch 1727/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0195\n",
      "Epoch 1728/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 1729/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0179\n",
      "Epoch 1730/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0190\n",
      "Epoch 1731/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0194\n",
      "Epoch 1732/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 1733/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 1734/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0180\n",
      "Epoch 1735/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0198\n",
      "Epoch 1736/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0191\n",
      "Epoch 1737/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0042 - val_loss: 0.0173\n",
      "Epoch 1738/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0187\n",
      "Epoch 1739/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 1740/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0058 - val_loss: 0.0195\n",
      "Epoch 1741/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1742/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1743/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0186\n",
      "Epoch 1744/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0189\n",
      "Epoch 1745/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0194\n",
      "Epoch 1746/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0057 - val_loss: 0.0195\n",
      "Epoch 1747/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0196\n",
      "Epoch 1748/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 1749/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0187\n",
      "Epoch 1751/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0201\n",
      "Epoch 1752/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0191\n",
      "Epoch 1753/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0196\n",
      "Epoch 1754/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0043 - val_loss: 0.0199\n",
      "Epoch 1755/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0038 - val_loss: 0.0191\n",
      "Epoch 1756/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0040 - val_loss: 0.0205\n",
      "Epoch 1757/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0057 - val_loss: 0.0267\n",
      "Epoch 1758/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0073 - val_loss: 0.0198\n",
      "Epoch 1759/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0202\n",
      "Epoch 1760/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0064 - val_loss: 0.0177\n",
      "Epoch 1761/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0218\n",
      "Epoch 1762/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0186\n",
      "Epoch 1763/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0197\n",
      "Epoch 1764/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1765/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0196\n",
      "Epoch 1766/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0196\n",
      "Epoch 1767/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0048 - val_loss: 0.0198\n",
      "Epoch 1768/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0219\n",
      "Epoch 1769/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0205\n",
      "Epoch 1770/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 1771/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0188\n",
      "Epoch 1772/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0196\n",
      "Epoch 1773/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0191\n",
      "Epoch 1774/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 1775/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0051 - val_loss: 0.0197\n",
      "Epoch 1776/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0195\n",
      "Epoch 1777/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0191\n",
      "Epoch 1778/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0194\n",
      "Epoch 1779/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0051 - val_loss: 0.0197\n",
      "Epoch 1780/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0049 - val_loss: 0.0200\n",
      "Epoch 1781/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0057 - val_loss: 0.0208\n",
      "Epoch 1782/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0200\n",
      "Epoch 1783/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0037 - val_loss: 0.0190\n",
      "Epoch 1784/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0039 - val_loss: 0.0197\n",
      "Epoch 1785/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0196\n",
      "Epoch 1786/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0040 - val_loss: 0.0195\n",
      "Epoch 1787/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0045 - val_loss: 0.0191\n",
      "Epoch 1788/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0043 - val_loss: 0.0191\n",
      "Epoch 1789/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0190\n",
      "Epoch 1790/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0047 - val_loss: 0.0197\n",
      "Epoch 1791/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0185\n",
      "Epoch 1792/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0201\n",
      "Epoch 1793/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0052 - val_loss: 0.0196\n",
      "Epoch 1794/2000\n",
      "1312/1312 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0201\n",
      "Epoch 1795/2000\n",
      "1312/1312 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1796/2000\n",
      "1312/1312 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0200\n",
      "Epoch 1797/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0180\n",
      "Epoch 1798/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0040 - val_loss: 0.0209\n",
      "Epoch 1799/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0047 - val_loss: 0.0205\n",
      "Epoch 1800/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0048 - val_loss: 0.0181\n",
      "Epoch 1801/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0050 - val_loss: 0.0187\n",
      "Epoch 1802/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0045 - val_loss: 0.0192\n",
      "Epoch 1803/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0051 - val_loss: 0.0188\n",
      "Epoch 1804/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0045 - val_loss: 0.0192\n",
      "Epoch 1805/2000\n",
      "1312/1312 [==============================] - 0s 86us/step - loss: 0.0046 - val_loss: 0.0185\n",
      "Epoch 1806/2000\n",
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0045 - val_loss: 0.0185\n",
      "Epoch 1807/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0049 - val_loss: 0.0181\n",
      "Epoch 1808/2000\n",
      "1312/1312 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0200\n",
      "Epoch 1809/2000\n",
      "1312/1312 [==============================] - 0s 97us/step - loss: 0.0054 - val_loss: 0.0184\n",
      "Epoch 1810/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0177\n",
      "Epoch 1811/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0193\n",
      "Epoch 1812/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0209\n",
      "Epoch 1813/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0180\n",
      "Epoch 1814/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0176\n",
      "Epoch 1815/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0174\n",
      "Epoch 1816/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0048 - val_loss: 0.0204\n",
      "Epoch 1817/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0047 - val_loss: 0.0196\n",
      "Epoch 1818/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0050 - val_loss: 0.0183\n",
      "Epoch 1819/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0047 - val_loss: 0.0195\n",
      "Epoch 1820/2000\n",
      "1312/1312 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0188\n",
      "Epoch 1821/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0042 - val_loss: 0.0182\n",
      "Epoch 1822/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0043 - val_loss: 0.0198\n",
      "Epoch 1823/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 1824/2000\n",
      "1312/1312 [==============================] - 0s 86us/step - loss: 0.0045 - val_loss: 0.0214\n",
      "Epoch 1825/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312/1312 [==============================] - 0s 87us/step - loss: 0.0042 - val_loss: 0.0185\n",
      "Epoch 1826/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0232\n",
      "Epoch 1827/2000\n",
      "1312/1312 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0191\n",
      "Epoch 1828/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0045 - val_loss: 0.0206\n",
      "Epoch 1829/2000\n",
      "1312/1312 [==============================] - 0s 103us/step - loss: 0.0046 - val_loss: 0.0188\n",
      "Epoch 1830/2000\n",
      "1312/1312 [==============================] - 0s 102us/step - loss: 0.0048 - val_loss: 0.0199\n",
      "Epoch 1831/2000\n",
      "1312/1312 [==============================] - 0s 101us/step - loss: 0.0039 - val_loss: 0.0207\n",
      "Epoch 1832/2000\n",
      "1312/1312 [==============================] - 0s 100us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 1833/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0205\n",
      "Epoch 1834/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 1835/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0221\n",
      "Epoch 1836/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0192\n",
      "Epoch 1837/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0175\n",
      "Epoch 1838/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 1839/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0039 - val_loss: 0.0178\n",
      "Epoch 1840/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0200\n",
      "Epoch 1841/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0041 - val_loss: 0.0192\n",
      "Epoch 1842/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0206\n",
      "Epoch 1843/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0188\n",
      "Epoch 1844/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1845/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0215\n",
      "Epoch 1846/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0048 - val_loss: 0.0202\n",
      "Epoch 1847/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0053 - val_loss: 0.0203\n",
      "Epoch 1848/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1849/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0184\n",
      "Epoch 1850/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0191\n",
      "Epoch 1851/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0181\n",
      "Epoch 1852/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0173\n",
      "Epoch 1853/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0040 - val_loss: 0.0188\n",
      "Epoch 1854/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0198\n",
      "Epoch 1855/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0196\n",
      "Epoch 1856/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0186\n",
      "Epoch 1857/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0215\n",
      "Epoch 1858/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 1859/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0039 - val_loss: 0.0186\n",
      "Epoch 1860/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0043 - val_loss: 0.0205\n",
      "Epoch 1861/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0196\n",
      "Epoch 1862/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0175\n",
      "Epoch 1863/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0059 - val_loss: 0.0184\n",
      "Epoch 1864/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0053 - val_loss: 0.0174\n",
      "Epoch 1865/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0191\n",
      "Epoch 1866/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0203\n",
      "Epoch 1867/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 1868/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0198\n",
      "Epoch 1869/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0182\n",
      "Epoch 1870/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0190\n",
      "Epoch 1871/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0193\n",
      "Epoch 1872/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0197\n",
      "Epoch 1873/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0207\n",
      "Epoch 1874/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0181\n",
      "Epoch 1875/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0187\n",
      "Epoch 1876/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0177\n",
      "Epoch 1877/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0200\n",
      "Epoch 1878/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0194\n",
      "Epoch 1879/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0191\n",
      "Epoch 1880/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0179\n",
      "Epoch 1881/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0056 - val_loss: 0.0183\n",
      "Epoch 1882/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0051 - val_loss: 0.0169\n",
      "Epoch 1883/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0178\n",
      "Epoch 1884/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0042 - val_loss: 0.0185\n",
      "Epoch 1885/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0190\n",
      "Epoch 1886/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0198\n",
      "Epoch 1887/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0190\n",
      "Epoch 1888/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0166\n",
      "Epoch 1889/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 1890/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0185\n",
      "Epoch 1891/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0045 - val_loss: 0.0182\n",
      "Epoch 1892/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0186\n",
      "Epoch 1893/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0055 - val_loss: 0.0198\n",
      "Epoch 1894/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0168\n",
      "Epoch 1895/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0208\n",
      "Epoch 1896/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0050 - val_loss: 0.0181\n",
      "Epoch 1897/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0054 - val_loss: 0.0185\n",
      "Epoch 1898/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0041 - val_loss: 0.0186\n",
      "Epoch 1899/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0201\n",
      "Epoch 1900/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1901/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0214\n",
      "Epoch 1902/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0043 - val_loss: 0.0194\n",
      "Epoch 1903/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0196\n",
      "Epoch 1904/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0198\n",
      "Epoch 1905/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0215\n",
      "Epoch 1906/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0189\n",
      "Epoch 1907/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0213\n",
      "Epoch 1908/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0193\n",
      "Epoch 1909/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0189\n",
      "Epoch 1910/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 1911/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0186\n",
      "Epoch 1912/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0210\n",
      "Epoch 1913/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0191\n",
      "Epoch 1914/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 1915/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0044 - val_loss: 0.0196\n",
      "Epoch 1916/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0184\n",
      "Epoch 1917/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0194\n",
      "Epoch 1918/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0046 - val_loss: 0.0183\n",
      "Epoch 1919/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0212\n",
      "Epoch 1920/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0179\n",
      "Epoch 1921/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0185\n",
      "Epoch 1922/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0052 - val_loss: 0.0185\n",
      "Epoch 1923/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0049 - val_loss: 0.0193\n",
      "Epoch 1924/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0182\n",
      "Epoch 1925/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0177\n",
      "Epoch 1926/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0191\n",
      "Epoch 1927/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0171\n",
      "Epoch 1928/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0075 - val_loss: 0.0184\n",
      "Epoch 1929/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0046 - val_loss: 0.0190\n",
      "Epoch 1930/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0037 - val_loss: 0.0188\n",
      "Epoch 1931/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 1932/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1933/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0169\n",
      "Epoch 1934/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0045 - val_loss: 0.0179\n",
      "Epoch 1935/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0206\n",
      "Epoch 1936/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0189\n",
      "Epoch 1937/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0185\n",
      "Epoch 1938/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0045 - val_loss: 0.0219\n",
      "Epoch 1939/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0050 - val_loss: 0.0182\n",
      "Epoch 1940/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0210\n",
      "Epoch 1941/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 1942/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0209\n",
      "Epoch 1943/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0043 - val_loss: 0.0194\n",
      "Epoch 1944/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0204\n",
      "Epoch 1945/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0040 - val_loss: 0.0201\n",
      "Epoch 1946/2000\n",
      "1312/1312 [==============================] - 0s 95us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1947/2000\n",
      "1312/1312 [==============================] - 0s 94us/step - loss: 0.0042 - val_loss: 0.0199\n",
      "Epoch 1948/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0188\n",
      "Epoch 1949/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0050 - val_loss: 0.0198\n",
      "Epoch 1950/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0187\n",
      "Epoch 1951/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0189\n",
      "Epoch 1952/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0188\n",
      "Epoch 1953/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0178\n",
      "Epoch 1954/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0065 - val_loss: 0.0195\n",
      "Epoch 1955/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0198\n",
      "Epoch 1956/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0041 - val_loss: 0.0182\n",
      "Epoch 1957/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0179\n",
      "Epoch 1958/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0042 - val_loss: 0.0202\n",
      "Epoch 1959/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0175\n",
      "Epoch 1960/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0040 - val_loss: 0.0190\n",
      "Epoch 1961/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0201\n",
      "Epoch 1962/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0171\n",
      "Epoch 1963/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0191\n",
      "Epoch 1964/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0048 - val_loss: 0.0181\n",
      "Epoch 1965/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0048 - val_loss: 0.0201\n",
      "Epoch 1966/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0186\n",
      "Epoch 1967/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0210\n",
      "Epoch 1968/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 1969/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0044 - val_loss: 0.0175\n",
      "Epoch 1970/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0191\n",
      "Epoch 1971/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0047 - val_loss: 0.0181\n",
      "Epoch 1972/2000\n",
      "1312/1312 [==============================] - 0s 93us/step - loss: 0.0045 - val_loss: 0.0182\n",
      "Epoch 1973/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0197\n",
      "Epoch 1974/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0054 - val_loss: 0.0216\n",
      "Epoch 1975/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0175\n",
      "Epoch 1976/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0044 - val_loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1977/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0180\n",
      "Epoch 1978/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0183\n",
      "Epoch 1979/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0191\n",
      "Epoch 1980/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 1981/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0046 - val_loss: 0.0188\n",
      "Epoch 1982/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0185\n",
      "Epoch 1983/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0188\n",
      "Epoch 1984/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0190\n",
      "Epoch 1985/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0052 - val_loss: 0.0215\n",
      "Epoch 1986/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 1987/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 1988/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0178\n",
      "Epoch 1989/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0049 - val_loss: 0.0174\n",
      "Epoch 1990/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0050 - val_loss: 0.0195\n",
      "Epoch 1991/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0039 - val_loss: 0.0189\n",
      "Epoch 1992/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0042 - val_loss: 0.0199\n",
      "Epoch 1993/2000\n",
      "1312/1312 [==============================] - 0s 88us/step - loss: 0.0042 - val_loss: 0.0196\n",
      "Epoch 1994/2000\n",
      "1312/1312 [==============================] - 0s 92us/step - loss: 0.0044 - val_loss: 0.0197\n",
      "Epoch 1995/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0204\n",
      "Epoch 1996/2000\n",
      "1312/1312 [==============================] - 0s 90us/step - loss: 0.0045 - val_loss: 0.0211\n",
      "Epoch 1997/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0194\n",
      "Epoch 1998/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0048 - val_loss: 0.0202\n",
      "Epoch 1999/2000\n",
      "1312/1312 [==============================] - 0s 89us/step - loss: 0.0051 - val_loss: 0.0187\n",
      "Epoch 2000/2000\n",
      "1312/1312 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfb27a6d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=keras.optimizers.Nadam())\n",
    "model.fit(X_train, y_train_log, epochs=2000, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(y_pred, y_train_log, 'ro')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Reality')\n",
    "ax.plot([y_train_log.min(), y_train_log.max()], \n",
    "        [y_train_log.min(), y_train_log.max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(model.predict(X_test)[:,0])\n",
    "result=pd.DataFrame({'Id':range(1461, 2920), 'SalePrice':y_pred})\n",
    "result.to_csv(\"dataset/submission2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
